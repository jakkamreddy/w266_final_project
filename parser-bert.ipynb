{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is parsing i2b2 training data and annotating it with the CoNLL BIO scheme, which has this form:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[record#] [word] [POS tag] [chunk tag] [NER tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk import pos_tag, RegexpParser\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = \"./data/annotations/\"  #  \"entries\" or \"annotations\"\n",
    "test = os.listdir(dir_name)\n",
    "\n",
    "for filename in test:\n",
    "    noExtension = filename.split(\".\")[0]\n",
    "    #print (filename)\n",
    "\n",
    "    if filename[0] != \".\":\n",
    "        os.rename(dir_name+filename, dir_name+noExtension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: all anotations have a corresponding entry. 259\n"
     ]
    }
   ],
   "source": [
    "a_ids = []\n",
    "e_ids = []\n",
    "\n",
    "for filename in os.listdir(\"./data/annotations\"):\n",
    "    if filename[0] != \".\":  # ignore hidden files\n",
    "        a_ids.append(int(filename))\n",
    "for filename in os.listdir(\"./data/entries\"):\n",
    "    if filename[0] != \".\": \n",
    "        e_ids.append(int(filename))\n",
    "    \n",
    "a_ids = tuple(sorted(a_ids)) \n",
    "e_ids = tuple(sorted(e_ids))\n",
    "\n",
    "intersection = list(set(a_ids) & set(e_ids))\n",
    "if len(intersection) == len(a_ids):\n",
    "    print(\"Success: all anotations have a corresponding entry.\", len(intersection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "995723\n"
     ]
    }
   ],
   "source": [
    "print(a_ids[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build annotation and entry corpora\n",
    "\n",
    "a_corpus = []\n",
    "e_corpus = []\n",
    "\n",
    "# only annotations and corresponding files\n",
    "for file in a_ids:\n",
    "    path = \"./data/annotations/\" + str(file)\n",
    "    with open(path) as f:\n",
    "        content = f.read().splitlines()\n",
    "        a_corpus.append(content)\n",
    "\n",
    "    path = \"./data/entries/\" + str(file)\n",
    "    with open(path) as f:\n",
    "        #content = f.readlines()\n",
    "        content = f.read().splitlines()\n",
    "        e_corpus.append(content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m=\"cefpodoxime\" 48:0 48:0|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"aspart\" 68:2 68:2|| do=\"4 units\" 68:3 68:4|| mo=\"subcutaneous\" 68:5 68:5|| f=\"before dinner\" 68:6 68:7|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"lantus\" 32:9 32:9|| do=\"7 units\" 32:6 32:7|| mo=\"nm\"|| f=\"q.a.m....q.p.m.\" 32:10 32:10|| du=\"nm\"|| r=\"nm\"|| e=\"stop\"|| t=\"past\"|| c=\"factual\"|| ln=\"list\"', 'm=\"cefpodoxime\" 48:6 48:6|| do=\"nm\"|| mo=\"nm\"|| f=\"after dialysis on monday-wednesday-friday.\" 49:1 49:4|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"narrative\"', 'm=\"tylenol\" 74:3 74:3|| do=\"650 mg\" 74:4 74:5|| mo=\"nm\"|| f=\"p.r.n.\" 74:6 74:6|| du=\"nm\"|| r=\"pain\" 74:7 74:7|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"aspart\" 70:2 70:2|| do=\"0 units\" 71:8 71:9|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"blood sugar\" 71:4 71:5|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"cefpodoxime\" 24:2 24:2|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"list\"', 'm=\"ativan\" 11:6 11:6|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"start-continue\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"aspart\" 33:5 33:5|| do=\"5 units\" 33:3 33:4|| mo=\"nm\"|| f=\"q.a.c. breakfast and lunch\" 33:6 33:9|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"narrative\"', 'm=\"flagyl\" 61:5 61:5|| do=\"500 mg\" 61:6 61:7|| mo=\"p.o.\" 61:8 61:8|| f=\"t.i.d.\" 61:9 61:9|| du=\"for 14 days\" 61:10 61:12|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"haldol\" 19:2 19:2|| do=\"nm\"|| mo=\"nm\"|| f=\"p.r.n.\" 19:3 19:3|| du=\"nm\"|| r=\"behavior.\" 19:4 19:5|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"depakote\" 58:6 58:6|| do=\"250 mg\" 58:7 58:8|| mo=\"p.o.\" 58:9 58:9|| f=\"b.i.d.\" 58:10 58:10|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"ceftriaxone\" 47:3 47:3|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"stop\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"folate\" 58:12 58:12|| do=\"1 mg\" 58:13 59:0|| mo=\"p.o.\" 59:1 59:1|| f=\"daily\" 59:2 59:2|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"phoslo\" 58:0 58:0|| do=\"2001 mg\" 58:1 58:2|| mo=\"p.o.\" 58:3 58:3|| f=\"t.i.d.\" 58:4 58:4|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"haldol\" 59:4 59:4|| do=\"1 mg\" 59:5 59:6|| mo=\"iv\" 59:7 59:7|| f=\"monday-wednesday-friday given prior to hemodialysis\" 59:9 60:2|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"albuterol butt paste\" 73:6 73:8|| do=\"nm\"|| mo=\"topical\" 73:9 73:9|| f=\"daily , and then p.r.n.\" 73:10 74:2|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"haldol\" 15:2 15:2|| do=\"1 mg\" 15:8 15:9|| mo=\"nm\"|| f=\"monday-wednesday-friday...before hemodialysis...p.r.n.\" 15:7 15:7,16:0 16:1,16:5 16:5||| du=\"nm\"|| r=\"agitation.\" 16:6 16:6|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"aspart\" 35:13 35:13|| do=\"one to two units\" 35:8 35:11|| mo=\"nm\"|| f=\"during the night\" 36:0 36:2|| du=\"nm\"|| r=\"nm\"|| e=\"start-continue\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"aspart\" 70:2 70:2|| do=\"1 unit\" 72:2 72:3|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"blood sugar\" 71:11 71:12|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"flagyl.\" 23:8 23:8|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"haldol\" 15:2 15:2|| do=\"1 mg\" 16:3 16:4|| mo=\"nm\"|| f=\"monday-wednesday-friday...before hemodialysis...p.r.n.\" 15:7 15:7,16:0 16:1,16:5 16:5||| du=\"nm\"|| r=\"agitation.\" 16:6 16:6|| e=\"stop\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"insulin\" 36:4 36:4|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"narrative\"', 'm=\"aspart\" 39:0 39:0|| do=\"halved\" 39:3 39:3|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"stop\"|| t=\"past\"|| c=\"factual\"|| ln=\"list\"', 'm=\"aspart\" 68:2 68:2|| do=\"5 units\" 69:4 69:5|| mo=\"subcutaneous\" 69:6 69:6|| f=\"before lunch\" 69:7 70:0|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"depakote\" 17:7 17:7|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"narrative\"', 'm=\"ceftriaxone\" 23:5 23:5|| do=\"nm\"|| mo=\"iv\" 23:6 23:6|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"flagyl\" 24:4 24:4|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"narrative\"', 'm=\"aspart\" 70:2 70:2|| do=\"2 units\" 73:3 73:4|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"blood sugar\" 72:12 73:0|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"cefpodoxime\" 63:3 63:3|| do=\"200 mg\" 63:4 63:5|| mo=\"p.o.\" 63:6 63:6|| f=\"three times a week on monday-wednesday-friday...after hemodialysis\" 63:7 64:0|| du=\"for eight doses\" 64:1 64:3|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"gabapentin\" 62:11 62:11|| do=\"300 mg\" 62:12 62:13|| mo=\"p.o.\" 63:0 63:0|| f=\"q.h.s.\" 63:1 63:1|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"aspart\" 68:2 68:2|| do=\"5 units\" 68:9 68:10|| mo=\"subcutaneous\" 69:0 69:0|| f=\"before breakfast\" 69:1 69:2|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"loperamide\" 77:6 77:6|| do=\"2 mg\" 77:7 77:8|| mo=\"p.o.\" 77:9 77:9|| f=\"q. 8h. p.r.n.\" 77:10 77:12|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"tylenol\" 74:3 74:3|| do=\"650 mg\" 74:4 74:5|| mo=\"nm\"|| f=\"p.r.n.\" 74:6 74:6|| du=\"nm\"|| r=\"temperature\" 75:0 75:0|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"depakote\" 18:8 18:8|| do=\"250 mg\" 18:10 19:0|| mo=\"nm\"|| f=\"b.i.d.\" 18:9 18:9|| du=\"nm\"|| r=\"nm\"|| e=\"continue\"|| t=\"present\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"aspart\" 70:2 70:2|| do=\"sliding scale\" 70:3 70:4|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"blood sugar\" 70:7 70:8|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"antibiotics\" 47:1 47:1|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"pneumonia\" 46:4 46:4|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"lisinopril\" 60:10 60:10|| do=\"80 mg\" 61:0 61:1|| mo=\"p.o.\" 61:2 61:2|| f=\"daily\" 61:3 61:3|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"nephrocaps\" 65:0 65:0|| do=\"one tablet\" 65:1 65:2|| mo=\"p.o.\" 65:3 65:3|| f=\"daily\" 65:4 65:4|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"depakote\" 15:0 15:0|| do=\"250 mg\" 14:6 14:7|| mo=\"nm\"|| f=\"b.i.d.\" 14:8 14:8|| du=\"nm\"|| r=\"nm\"|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"haldol\" 15:2 15:2|| do=\"1 mg\" 15:8 15:9|| mo=\"nm\"|| f=\"monday-wednesday-friday...before hemodialysis...p.r.n.\" 15:7 15:7|| du=\"nm\"|| r=\"agitation.\" 16:6 16:6|| e=\"start\"|| t=\"nm\"|| c=\"factual\"|| ln=\"list\"', 'm=\"thiamine\" 61:14 61:14|| do=\"100 mg\" 62:0 62:1|| mo=\"p.o.\" 62:2 62:2|| f=\"daily\" 62:3 62:3|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"tylenol\" 74:3 74:3|| do=\"650 mg\" 74:4 74:5|| mo=\"nm\"|| f=\"p.r.n.\" 74:6 74:6|| du=\"nm\"|| r=\"headache\" 74:9 74:9|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"insulin\" 53:8 53:8|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"nexium\" 66:7 66:7|| do=\"20 mg\" 66:8 66:9|| mo=\"p.o.\" 66:10 66:10|| f=\"daily\" 66:11 66:11|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"sevelamer\" 65:6 65:6|| do=\"2004 mg\" 65:7 65:8|| mo=\"p.o.\" 65:9 65:9|| f=\"t.i.d.\" 65:10 65:10|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"lantus\" 67:0 67:0|| do=\"7 units\" 67:1 67:2|| mo=\"subcutaneous\" 67:3 67:3|| f=\"b.i.d. once in the morning and once evening\" 67:4 68:0|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"labetalol\" 60:4 60:4|| do=\"350 mg\" 60:5 60:6|| mo=\"p.o.\" 60:7 60:7|| f=\"b.i.d.\" 60:8 60:8|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"advair diskus 250/50\" 66:0 66:2|| do=\"one puff\" 66:3 66:4|| mo=\"nm\"|| f=\"b.i.d.\" 66:5 66:5|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"albuterol inhaler\" 75:2 75:3|| do=\"nm\"|| mo=\"nm\"|| f=\"p.r.n.\" 75:4 75:4|| du=\"nm\"|| r=\"wheezing\" 75:5 75:5|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"norvasc\" 62:5 62:5|| do=\"10 mg\" 62:6 62:7|| mo=\"p.o.\" 62:8 62:8|| f=\"daily\" 62:9 62:9|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"haldol\" 75:7 75:7|| do=\"1 mg\" 75:8 75:9|| mo=\"iv\" 75:10 75:10|| f=\"q. 6h. p.r.n.\" 75:11 76:1|| du=\"nm\"|| r=\"agitation.\" 76:2 76:2|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"ceftriaxone\" 47:3 47:3|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"start\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"', 'm=\"aspart\" 70:2 70:2|| do=\"2 units\" 72:9 72:10|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"blood sugar\" 72:5 72:6|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"aspart\" 34:2 34:2|| do=\"4 units\" 33:11 34:0|| mo=\"nm\"|| f=\"q.a.c. dinner.\" 34:3 34:4|| du=\"nm\"|| r=\"nm\"|| e=\"nm\"|| t=\"nm\"|| c=\"nm\"|| ln=\"list\"', 'm=\"flagyl\" 48:2 48:2|| do=\"nm\"|| mo=\"nm\"|| f=\"nm\"|| du=\"nm\"|| r=\"nm\"|| e=\"start-continue\"|| t=\"past\"|| c=\"factual\"|| ln=\"narrative\"']\n"
     ]
    }
   ],
   "source": [
    "print(a_corpus[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  [\"id\", \"row\", \"offset\", \"word\", \"POS\", \"chunk\", \"NER\"]\n",
    "entries_cols = [\"id\", \"row\", \"offset\", \"word\"]\n",
    "entries_df = pd.DataFrame(columns=entries_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, row, offset, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_cols = [\"id\", \"NER_tag\", \"row\", \"offset\", \"length\"]\n",
    "annotations_df = pd.DataFrame(columns=annotations_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, NER_tag, row, offset, length]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medication annotations:  9220\n",
      "Dosage annotations:  4626\n",
      "Mode annotations:  3477\n",
      "Frequency annotations:  4186\n",
      "Duration annotations:  570\n",
      "Reason annotations:  1662\n"
     ]
    }
   ],
   "source": [
    "med_count = 0\n",
    "dosage_count = 0\n",
    "mode_count = 0\n",
    "freq_count = 0\n",
    "dur_count = 0\n",
    "reason_count = 0\n",
    "\n",
    "for document in a_corpus:\n",
    "    for line in document:\n",
    "        if \"m=\\\"nm\\\"\" not in line:\n",
    "            med_count += 1\n",
    "        if \"do=\\\"nm\\\"\" not in line:\n",
    "            dosage_count += 1\n",
    "        if \"mo=\\\"nm\\\"\" not in line:\n",
    "            mode_count += 1\n",
    "        if \"f=\\\"nm\\\"\" not in line:\n",
    "            freq_count += 1\n",
    "        if \"du=\\\"nm\\\"\" not in line:\n",
    "            dur_count += 1\n",
    "        if \"r=\\\"nm\\\"\" not in line:\n",
    "            reason_count += 1\n",
    "        \n",
    "print(\"Medication annotations: \", med_count)\n",
    "print(\"Dosage annotations: \", dosage_count)\n",
    "print(\"Mode annotations: \", mode_count)\n",
    "print(\"Frequency annotations: \", freq_count)\n",
    "print(\"Duration annotations: \", dur_count)\n",
    "print(\"Reason annotations: \", reason_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build annotations data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_df = pd.DataFrame(columns=annotations_cols)  # reset df\n",
    "tmp_list = []\n",
    "\n",
    "for i, document in enumerate(a_corpus):\n",
    "    \n",
    "    for row in document:\n",
    "        row = row.split(\"||\")\n",
    "        #print(row, \"\\n\")\n",
    "        \n",
    "        for tag in row: \n",
    "            tag = tag.split(\"=\")\n",
    "            if len(tag) > 1:\n",
    "                if \":\" in tag[1]:\n",
    "                    tag_label = tag[0].lstrip(\" \")\n",
    "                    tag_row_a = tag[1].split(\" \")[-2:][0].split(\":\")[0]\n",
    "                    tag_row_b = tag[1].split(\" \")[-2:][1].split(\":\")[0]\n",
    "                    #print(tag_label, tag_row_a, tag_row_b)\n",
    "                \n",
    "                    # some annotations have non-standard formatting (losing 64 instances)\n",
    "                    try:\n",
    "                        tag_offset_a = int(tag[1].split(\" \")[-2:][0].split(\":\")[1])\n",
    "                        tag_offset_b = int(tag[1].split(\" \")[-2:][1].split(\":\")[1])\n",
    "                        length = tag_offset_b - tag_offset_a + 1\n",
    "                        #print(tag_offset_a, tag_offset_b, length)\n",
    "\n",
    "                        # 1 row = 1 token with a tag\n",
    "                        first = True\n",
    "                        BIO_tag = \"B-\"\n",
    "                        if length > 1 and tag_row_a == tag_row_b:\n",
    "                            for offset in range(tag_offset_a, tag_offset_b+1):\n",
    "                                if first: \n",
    "                                    tag_label = BIO_tag + tag_label\n",
    "                                    first = False\n",
    "                                else:\n",
    "                                    tag_label = tag_label.replace(\"B-\", \"I-\")\n",
    "                                tmp_list.append([a_ids[i], tag_label, tag_row_a, offset, 1])\n",
    "                                #if \"I-\" in tag_label:\n",
    "                                #    print(row, tag_label, tag)\n",
    "                        # TODO: tags over line breaks\n",
    "                        else:\n",
    "                            tmp_list.append([a_ids[i], BIO_tag + tag_label, tag_row_a, tag_offset_a, length])\n",
    "                    except:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "annotations_df = pd.DataFrame(tmp_list, columns=annotations_cols)\n",
    "annotations_df.reset_index(inplace=True)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B-m', 'B-do', 'I-do', 'B-mo', 'B-f', 'I-f', 'I-m', 'B-du', 'I-du',\n",
       "       'B-r', 'I-r', 'I-mo'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df[\"NER_tag\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36665, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df = annotations_df.drop(columns=[\"index\", \"length\"])\n",
    "annotations_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-m</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-do</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11995</td>\n",
       "      <td>I-do</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-mo</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-f</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id NER_tag row  offset\n",
       "0  11995     B-m  37      12\n",
       "1  11995    B-do  37      13\n",
       "2  11995    I-do  37      14\n",
       "3  11995    B-mo  38       0\n",
       "4  11995     B-f  38       1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, row, offset, word]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RECORD', '#11995']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_corpus[0][0].split(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build entries data frame"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "List of token modifications:\n",
    "    - \"|\": ignored\n",
    "    - \".\" removed from end of token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries_df = pd.DataFrame(columns=entries_cols)  # reset df\n",
    "tmp_list = []\n",
    "\n",
    "for doc_i, document in enumerate(e_corpus):\n",
    "    \n",
    "    tmp_list.append([0, 0, 0, \"-DOCSTART-\"])\n",
    "    tmp_list.append([0, 0, 0, \"-EMPTYLINE-\"])\n",
    "    \n",
    "    for row_i, row in enumerate(document):\n",
    "        row_split = row.split(\" \")\n",
    "        for word_i, word in enumerate(row_split):\n",
    "            word = word.rstrip(\".\")  # strip \".\" from end of word\n",
    "            word = word.replace(\"\\t\", \"\")\n",
    "            word_id = a_ids[doc_i]\n",
    "            word_row = row_i+1  # 1-based indexing \n",
    "            word_offset = word_i # 0-based indexing\n",
    "            \n",
    "            if len(word) > 0 and \"|\" not in word:\n",
    "                tmp_list.append([word_id, word_row, word_offset, word])\n",
    "        \n",
    "    tmp_list.append([0, 0, 0, \"-EMPTYLINE-\"])\n",
    "\n",
    "entries_df = pd.DataFrame(tmp_list, columns=entries_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-EMPTYLINE-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RECORD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11995</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>#11995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11995</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>785297081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  row  offset         word\n",
       "0      0    0       0   -DOCSTART-\n",
       "1      0    0       0  -EMPTYLINE-\n",
       "2  11995    1       0       RECORD\n",
       "3  11995    1       1       #11995\n",
       "4  11995    2       0    785297081"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>row</th>\n",
       "      <th>offset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-m</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-do</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>11995</td>\n",
       "      <td>I-do</td>\n",
       "      <td>37</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-mo</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11995</td>\n",
       "      <td>B-f</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id NER_tag row  offset\n",
       "0  11995     B-m  37      12\n",
       "1  11995    B-do  37      13\n",
       "2  11995    I-do  37      14\n",
       "3  11995    B-mo  38       0\n",
       "4  11995     B-f  38       1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23676 named entities\n"
     ]
    }
   ],
   "source": [
    "ner_counter = [1 for i in annotations_df[\"NER_tag\"] if \"B-\" in i]\n",
    "print(len(ner_counter), \"named entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joing entries and annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure correct dtypes\n",
    "annotations_df[['id', 'row', 'offset']] = annotations_df[['id', 'row', 'offset']].apply(pd.to_numeric)\n",
    "annotations_df['NER_tag'] = annotations_df[\"NER_tag\"].astype(str)\n",
    "entries_df[['id', 'row', 'offset']] = entries_df[['id', 'row', 'offset']].apply(pd.to_numeric)\n",
    "entries_df[\"word\"] = entries_df[\"word\"].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.merge(entries_df, annotations_df, how=\"left\", on=['id', 'row', 'offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with missing data:\n",
      " id         False\n",
      "row        False\n",
      "offset     False\n",
      "word       False\n",
      "NER_tag     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# replace NaNs with \"O\"\n",
    "print(\"columns with missing data:\\n\", result_df.isna().any())\n",
    "result_df = result_df.fillna(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns with missing data:\n",
      " id         False\n",
      "row        False\n",
      "offset     False\n",
      "word       False\n",
      "NER_tag    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(\"columns with missing data:\\n\", result_df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-EMPTYLINE-</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#11995</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>785297081</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word NER_tag\n",
       "0   -DOCSTART-       O\n",
       "1  -EMPTYLINE-       O\n",
       "2       RECORD       O\n",
       "3       #11995       O\n",
       "4    785297081       O"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df.drop(columns=[\"id\", \"row\", \"offset\"])\n",
    "result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292887, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23670 named entities\n"
     ]
    }
   ],
   "source": [
    "# 71 fewer annotations than expected as annotations over line breaks are not included\n",
    "ner_counter = [1 for i in result_df[\"NER_tag\"] if \"B-\" in i]\n",
    "print(len(ner_counter), \"named entities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.chunk.regexp import RegexpChunkParser, ChunkRule, RegexpParser\n",
    "from nltk.tree import Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = result_df[\"word\"].tolist()\n",
    "text_pos = pos_tag(text)\n",
    "text_pos_list = [i[1] for i in text_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "292887"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['word', 'NER_tag'], dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"POS_tag\"] = text_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>NER_tag</th>\n",
       "      <th>POS_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-DOCSTART-</td>\n",
       "      <td>O</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-EMPTYLINE-</td>\n",
       "      <td>O</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RECORD</td>\n",
       "      <td>O</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>#11995</td>\n",
       "      <td>O</td>\n",
       "      <td>VBZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>785297081</td>\n",
       "      <td>O</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word NER_tag POS_tag\n",
       "0   -DOCSTART-       O      JJ\n",
       "1  -EMPTYLINE-       O      NN\n",
       "2       RECORD       O     NNP\n",
       "3       #11995       O     VBZ\n",
       "4    785297081       O      CD"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CoNLL chunk tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = \"EU rejects German call to boycott British lamb.\".split(\" \")\n",
    "text_pos_test = pos_tag(text_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EU', 'NNP'),\n",
       " ('rejects', 'VBZ'),\n",
       " ('German', 'JJ'),\n",
       " ('call', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('boycott', 'VB'),\n",
       " ('British', 'JJ'),\n",
       " ('lamb.', 'NN')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used for building regex \n",
    "grammar = r\"\"\"\n",
    "    NP: {<DT|PP\\$>?<JJ>*<NN.*>+} # noun phrase\n",
    "    PP: {<IN><NP>}               # prepositional phrase\n",
    "    VP: {<MD>?<VB.*><NP|PP>}     # verb phrase\n",
    "    CLAUSE: {<NP><VP>}           # full clause\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_0 = ChunkRule(\"<DT>?<JJ.*>*<NN.*>+\", \"More complete chunk NP sequences\")\n",
    "\n",
    "chunk_parser_np = RegexpChunkParser([rule_0],chunk_label='NP')\n",
    "\n",
    "chunk_result_tree_np = chunk_parser_np.parse(text_pos)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_tag_np = []\n",
    "\n",
    "for i in chunk_result_tree_np:\n",
    "    if isinstance(i, Tree):\n",
    "        for j in range(0, len(i)):\n",
    "            if j == 0:\n",
    "                # print(\"B-\" + i.label())\n",
    "                chunk_tag_np.append(\"B-\" + i.label())\n",
    "            else:\n",
    "                chunk_tag_np.append(\"I-\" + i.label())\n",
    "                # print(\"I-\" + i.label())\n",
    "    else:\n",
    "        # print(\"O\")\n",
    "        chunk_tag_np.append(\"O\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_tag_np) == result_df.shape[0]  # check that chunk col has same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-NP\n"
     ]
    }
   ],
   "source": [
    "print(chunk_tag_np[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verb phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule_1 = ChunkRule(\"<VBD|IN|\\.>\", \"Verb phrases\")\n",
    "\n",
    "chunk_parser_vp = RegexpChunkParser([rule_1],chunk_label='VP')\n",
    "\n",
    "chunk_result_tree_vp = chunk_parser_vp.parse(text_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_tag_vp = []\n",
    "\n",
    "for i in chunk_result_tree_vp:\n",
    "    if isinstance(i, Tree):\n",
    "        for j in range(0, len(i)):\n",
    "            if j == 0:\n",
    "                # print(\"B-\" + i.label())\n",
    "                chunk_tag_vp.append(\"B-\" + i.label())\n",
    "            else:\n",
    "                chunk_tag_vp.append(\"I-\" + i.label())\n",
    "                # print(\"I-\" + i.label())\n",
    "    else:\n",
    "        # print(\"O\")\n",
    "        chunk_tag_vp.append(\"O\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunk_tag_np) == result_df.shape[0] == len(chunk_tag_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment chunk tags with verb phrase tags\n",
    "for i, entry in enumerate(chunk_tag_np):\n",
    "    if entry == \"O\":\n",
    "        chunk_tag_np[i] = chunk_tag_vp[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are not prepositional phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df[\"chunk_tag\"] = chunk_tag_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df[['word', 'POS_tag', 'chunk_tag', 'NER_tag']]  # order columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292887, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word         object\n",
       "POS_tag      object\n",
       "chunk_tag    object\n",
       "NER_tag      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df[['word', 'POS_tag', 'chunk_tag', 'NER_tag']] = result_df[['word', 'POS_tag', 'chunk_tag', 'NER_tag']].astype(str)\n",
    "result_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292887, 4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result_df.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 858,\n",
       " 1697,\n",
       " 3431,\n",
       " 4962,\n",
       " 5695,\n",
       " 6844,\n",
       " 7849,\n",
       " 9098,\n",
       " 10547,\n",
       " 11288,\n",
       " 12705,\n",
       " 14868,\n",
       " 15652,\n",
       " 17041,\n",
       " 17999,\n",
       " 19023,\n",
       " 19868,\n",
       " 21178,\n",
       " 22324,\n",
       " 23121,\n",
       " 24181,\n",
       " 24926,\n",
       " 25972,\n",
       " 27166,\n",
       " 28662,\n",
       " 29917,\n",
       " 30987,\n",
       " 31920,\n",
       " 32863,\n",
       " 33791,\n",
       " 35066,\n",
       " 36329,\n",
       " 37519,\n",
       " 38954,\n",
       " 40043,\n",
       " 40990,\n",
       " 43497,\n",
       " 44199,\n",
       " 45649,\n",
       " 46329,\n",
       " 48408,\n",
       " 49194,\n",
       " 50338,\n",
       " 51388,\n",
       " 52032,\n",
       " 53184,\n",
       " 54281,\n",
       " 55002,\n",
       " 56258,\n",
       " 58451,\n",
       " 59389,\n",
       " 60584,\n",
       " 62185,\n",
       " 63048,\n",
       " 63493,\n",
       " 64114,\n",
       " 64933,\n",
       " 65746,\n",
       " 66883,\n",
       " 67573,\n",
       " 68806,\n",
       " 69511,\n",
       " 71456,\n",
       " 71980,\n",
       " 73313,\n",
       " 74016,\n",
       " 74737,\n",
       " 76888,\n",
       " 77523,\n",
       " 78329,\n",
       " 79608,\n",
       " 81095,\n",
       " 81602,\n",
       " 81920,\n",
       " 83001,\n",
       " 83871,\n",
       " 84583,\n",
       " 85146,\n",
       " 88984,\n",
       " 90103,\n",
       " 90815,\n",
       " 91146,\n",
       " 92126,\n",
       " 92975,\n",
       " 94225,\n",
       " 96274,\n",
       " 97001,\n",
       " 97738,\n",
       " 98920,\n",
       " 100363,\n",
       " 101251,\n",
       " 101944,\n",
       " 102590,\n",
       " 104309,\n",
       " 105007,\n",
       " 105843,\n",
       " 106819,\n",
       " 107723,\n",
       " 108346,\n",
       " 110127,\n",
       " 111580,\n",
       " 112989,\n",
       " 114300,\n",
       " 116003,\n",
       " 117855,\n",
       " 118664,\n",
       " 120439,\n",
       " 121889,\n",
       " 123318,\n",
       " 124041,\n",
       " 125058,\n",
       " 127179,\n",
       " 128125,\n",
       " 128825,\n",
       " 129411,\n",
       " 130542,\n",
       " 131363,\n",
       " 132208,\n",
       " 134810,\n",
       " 135398,\n",
       " 137238,\n",
       " 138312,\n",
       " 140363,\n",
       " 141610,\n",
       " 143262,\n",
       " 144421,\n",
       " 145731,\n",
       " 147039,\n",
       " 148273,\n",
       " 149612,\n",
       " 151155,\n",
       " 152156,\n",
       " 152665,\n",
       " 153533,\n",
       " 154504,\n",
       " 155470,\n",
       " 156725,\n",
       " 156927,\n",
       " 158229,\n",
       " 159268,\n",
       " 160193,\n",
       " 162188,\n",
       " 163230,\n",
       " 164005,\n",
       " 165674,\n",
       " 166719,\n",
       " 167998,\n",
       " 168568,\n",
       " 169015,\n",
       " 169670,\n",
       " 170630,\n",
       " 171902,\n",
       " 173123,\n",
       " 174993,\n",
       " 175944,\n",
       " 176832,\n",
       " 177791,\n",
       " 178192,\n",
       " 180357,\n",
       " 182117,\n",
       " 183386,\n",
       " 184317,\n",
       " 185574,\n",
       " 186351,\n",
       " 186871,\n",
       " 187854,\n",
       " 189676,\n",
       " 190170,\n",
       " 192055,\n",
       " 192720,\n",
       " 193746,\n",
       " 194829,\n",
       " 196595,\n",
       " 197476,\n",
       " 198212,\n",
       " 199419,\n",
       " 200408,\n",
       " 201555,\n",
       " 202026,\n",
       " 203009,\n",
       " 204641,\n",
       " 206177,\n",
       " 208905,\n",
       " 210836,\n",
       " 212169,\n",
       " 212790,\n",
       " 213568,\n",
       " 215047,\n",
       " 215997,\n",
       " 217397,\n",
       " 219442,\n",
       " 221120,\n",
       " 221994,\n",
       " 222450,\n",
       " 223262,\n",
       " 224717,\n",
       " 225350,\n",
       " 227144,\n",
       " 227837,\n",
       " 228642,\n",
       " 229106,\n",
       " 230002,\n",
       " 231034,\n",
       " 232857,\n",
       " 233576,\n",
       " 234344,\n",
       " 235205,\n",
       " 235976,\n",
       " 236615,\n",
       " 237477,\n",
       " 238980,\n",
       " 240393,\n",
       " 241269,\n",
       " 242389,\n",
       " 243284,\n",
       " 244975,\n",
       " 245390,\n",
       " 246798,\n",
       " 247200,\n",
       " 248717,\n",
       " 249278,\n",
       " 250686,\n",
       " 251894,\n",
       " 252429,\n",
       " 253107,\n",
       " 254229,\n",
       " 254827,\n",
       " 255921,\n",
       " 257237,\n",
       " 258994,\n",
       " 259921,\n",
       " 261474,\n",
       " 262472,\n",
       " 263242,\n",
       " 264758,\n",
       " 266294,\n",
       " 267220,\n",
       " 268044,\n",
       " 269263,\n",
       " 269796,\n",
       " 270473,\n",
       " 271770,\n",
       " 272284,\n",
       " 273616,\n",
       " 274158,\n",
       " 274893,\n",
       " 275962,\n",
       " 276442,\n",
       " 278000,\n",
       " 280776,\n",
       " 281405,\n",
       " 282091,\n",
       " 283533,\n",
       " 285130,\n",
       " 286159,\n",
       " 289132,\n",
       " 289629,\n",
       " 291634]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find indices of new documents\n",
    "result_df[result_df[\"word\"] == \"-DOCSTART-\"].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = 202062  \n",
    "dev = 247618\n",
    "result_train_df = result_df.iloc[:train]\n",
    "result_dev_df = result_df.iloc[train:dev]\n",
    "result_test_df = result_df.iloc[dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>POS_tag</th>\n",
       "      <th>chunk_tag</th>\n",
       "      <th>NER_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>292787</td>\n",
       "      <td>8</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292788</td>\n",
       "      <td>Prednisone</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>B-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292789</td>\n",
       "      <td>Prednisone</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>B-m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292790</td>\n",
       "      <td>5</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "      <td>B-do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292791</td>\n",
       "      <td>mg</td>\n",
       "      <td>NN</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>I-do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292882</td>\n",
       "      <td>6/10</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292883</td>\n",
       "      <td>T:</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292884</td>\n",
       "      <td>1/22</td>\n",
       "      <td>CD</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292885</td>\n",
       "      <td>[report_end]</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>292886</td>\n",
       "      <td>-EMPTYLINE-</td>\n",
       "      <td>NN</td>\n",
       "      <td>I-NP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                word POS_tag chunk_tag NER_tag\n",
       "292787             8      CD         O       O\n",
       "292788    Prednisone     NNP      B-NP     B-m\n",
       "292789    Prednisone     NNP      I-NP     B-m\n",
       "292790             5      CD         O    B-do\n",
       "292791            mg      NN      B-NP    I-do\n",
       "...              ...     ...       ...     ...\n",
       "292882          6/10      CD         O       O\n",
       "292883            T:     NNP      B-NP       O\n",
       "292884          1/22      CD         O       O\n",
       "292885  [report_end]     NNP      B-NP       O\n",
       "292886   -EMPTYLINE-      NN      I-NP       O\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape  (202062, 4)\n",
      "dev shape  (45556, 4)\n",
      "test shape  (45269, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape \", result_train_df.shape)\n",
    "print(\"dev shape \", result_dev_df.shape)\n",
    "print(\"test shape \", result_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"result_df_NER_POS_chunk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write to txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"train.txt\", result_train_df.values, fmt=\"%s\")\n",
    "np.savetxt(\"valid.txt\", result_dev_df.values, fmt=\"%s\")\n",
    "np.savetxt(\"test.txt\", result_test_df.values, fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
