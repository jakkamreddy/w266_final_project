{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Named Entity Recognition Model using  Clinical BERT </center></h1>\n",
    "<h4><center>Final Project W266</center></h4>\n",
    "\n",
    "\n",
    "<h3><center>SUMMARY</center></h3>\n",
    "\n",
    "In this notebook, we will look at implementing various BERT models to understand the significance of domain specific contexts with respect to fine tuning NER task.\n",
    "\n",
    "- The various BERT models used in the notebook are listed below.\n",
    "\n",
    "__BERT:__ \n",
    ">\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\", by Devlin/Chang/Lee/Toutanova, Google AI Language)\n",
    "\n",
    "__BioBERT:__ \n",
    ">A pre-trained biomedical language representation model for biomedical text mining by Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang\n",
    "\n",
    "__SciBERT:__\n",
    ">A Pretrained Language Model for Scientific Text by Iz Beltagy, Kyle Lo, Arman Cohan\n",
    "\n",
    "__ClinicalBert:__\n",
    ">Modeling Clinical Notes and Predicting Hospital Readmission by Kexin Huang, Jaan Altosaar, Rajesh Ranganath\n",
    "\n",
    ">Publicly Available Clinical BERT Embeddings by Emily Alsentzer, John R. Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann, Matthew B. A. McDermott\n",
    "\n",
    "\n",
    "Models used and their corresponding Corpora used:\n",
    "\n",
    "\n",
    "__Base Bert Cased -__  \n",
    "\n",
    ">Wikipedia + BookCorpus\n",
    "\n",
    "__BioBert Cased with PubMed and PMC - __\n",
    "\n",
    ">English Wikipedia, General BooksCorpus, General PubMed Abstracts, PMC Full-text articles\n",
    "\n",
    "__SciBert Cased -__\n",
    "\n",
    ">1.14M papers from Semantic Scholar (Ammar et al., 2018)\n",
    "\n",
    "__biobert_pretrain_output_all_notes_150000__\n",
    "\n",
    ">MIMIC text from all note types on BioBert\n",
    "\n",
    "\n",
    "__biobert_pretrain_output_disch_100000__\n",
    "\n",
    ">MIMIC text from all discharge summaries on BioBert\n",
    "\n",
    "\n",
    "We look at the effect of also fine-tuning BERT layers which are pre-trained with clinical context. \n",
    "\n",
    "\n",
    "### 1. Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "JA25,NNP,O\r\n",
      "Attending:,NNP,O\r\n",
      "SYDNEY,NNP,O\r\n",
      "DUESTERHAUS,NNP,O\r\n",
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "MG85,NNP,O\r\n",
      "EQ681/3978,NNP,O\r\n",
      "Batch:,NNP,O\r\n",
      "37609,CD,O\r\n",
      "Index,NNP,O\r\n",
      "No,NNP,O\r\n",
      "FHOW8875S8,NNP,O\r\n",
      "D:,NNP,O\r\n",
      "6/10,CD,O\r\n",
      "T:,NNP,O\r\n",
      "1/22,CD,O\r\n",
      "[report_end],NN,O\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 'ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Getting Started<a id=\"start\" />\n",
    "\n",
    "We start with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval[gpu] in /opt/conda/lib/python3.6/site-packages (0.0.12)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.16.3)\n",
      "Requirement already satisfied: tensorflow-gpu; extra == \"gpu\" in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.12.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (5.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.3.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (2.9.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.0.8)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.21.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.33.1)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.7.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.15.4)\n",
      "Requirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define maximam length of input 'sentences' (post tokenization).\n",
    "max_word = 40\n",
    "max_length = 64\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific bert Model \n",
    "\n",
    "#### Lets look at the model weights and the vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All Models.ipynb', 'scibert_scivocab_cased', 'cuda-repo-ubuntu1604-10-1-local-10.1.168-418.67_1.0-1_amd64.deb', 'ner_tags', 'vocab.txt', 'biobert_pretrain_output_disch_100000', 'biobert_working-pytorch-gpu_v1.ipynb', '.gnupg', 'clibert.bin', 'sentence_boundaries.ipynb', 'all_bert_models-50.ipynb', 'validation_sentences.csv', 'Baseline_model.ipynb', 'biobert.bin', 'scibert-pytorch-gpu.ipynb', 'biobert_pretrain_output_all_notes_150000', 'clinicalbert.bin', 'attention_decoder.py', 'bert_config.json', 'cuda-repo-ubuntu1604-10-1-local-10.1.105-418.39_1.0-1_amd64.deb', 'clinicalbert-pytorch-gpu_notes.ipynb', 'validation_ner.csv', 'pytorch_model.bin', 'sentence_model.h5', '.profile', '.config', 'ner_dataset.csv', 'clinicalbert_working-pytorch-gpu_v1.ipynb', 'data', 'convert_to_pytorch_wt.ipynb', '.keras', '.nv', '.bash_history', 'eos.pyc', 'connengine.ipynb', 'answers', 'parser-bert.ipynb', 'bert_working-pytorch-gpu_v1.ipynb', '.pytorch_pretrained_bert', 'best_model.hdf5', 'config.json', '.bashrc', 'validation_pred_ner.csv', '.ipython', 'biobert_v1.0_pubmed_pmc', 'clinicalbert_pytorch-gpu_disch.ipynb', 'all_bert_models.ipynb', 'weights.tar.gz', 'Inference_notebook.ipynb', 'RoBERTa_working-pytorch-gpu_v1_11_20.ipynb', '.ssh', 'Untitled.ipynb', 'weights', '.ipynb_checkpoints', 'words.csv', '.local', 'sentences.csv', 'sentence_model.json', '.cache', 'ner.csv']\n",
      "['vocab.txt', 'bert_config.json', 'pytorch_model.bin']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/root\"))\n",
    "print(os.listdir(\"/root/biobert_pretrain_output_disch_100000\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = '/root/biobert_pretrain_output_disch_100000/vocab.txt'\n",
    "MODEL = '/root/biobert_pretrain_output_disch_100000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing <a id=\"preprocess\" />\n",
    "\n",
    "### III.1 BERT Tokenizer<a id=\"tokenizer\" />\n",
    "\n",
    "We first start by defining and exploring the BERT tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/root/biobert_pretrain_output_disch_100000', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Who', 'was', 'Jim', 'He', '##nson', '?', '[SEP]', 'Jim', 'He', '##nson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print (tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('I\\'ll learn to swim in 12342 years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146, 112, 1325, 3858, 1106, 11231, 1107, 13414, 23117, 1201, 119]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faye']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([20958])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now we are ready to use it for our text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2. Extraction<a id=\"extract\"/>\n",
    "\n",
    "\n",
    "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
    "\n",
    "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
    "\n",
    "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
    "\n",
    "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
    "\n",
    "4) Create the mask ids. Mask out all of the padding tokens.\n",
    "\n",
    "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
    "\n",
    "To do this, we first define a helper function:\n",
    "\n",
    "* This section is from the lecture notebook of W266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['protest'],\n",
       " 'posToken': ['VB'],\n",
       " 'nerToken': ['O'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('protest', 'VB', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['Iraq'],\n",
       " 'posToken': ['NNP'],\n",
       " 'nerToken': ['B-geo'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('Iraq', 'NNP', 'B-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['1000', '##0'],\n",
       " 'posToken': ['CD', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('10000', 'CD', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert the text file into appropriate arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "\n",
    "with io.open('ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "word_count = 0\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "for line in text:\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    word, pos, ner = cleanLine.split(',')\n",
    "    \n",
    "    ner = ner[:-1]   # remove DOS token\n",
    "    \n",
    "    # if new sentence starts\n",
    "    if (word_count >= max_word -1):            \n",
    "            \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        \n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "\n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        posTokens = ['[posCLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + word\n",
    "        word_count = 0\n",
    "    \n",
    "    word_count += 1\n",
    "    addDict = addWord(word, pos, ner)\n",
    "\n",
    "    sentenceTokens += addDict['wordToken']\n",
    "    posTokens += addDict['posToken']\n",
    "    nerTokens += addDict['nerToken']\n",
    "\n",
    "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
    "sentLengthList = sentLengthList[2:]\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "posTokenList = posTokenList[2:]\n",
    "nerTokenList = nerTokenList[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "print(sentLengthList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2103, 1115, 1123, 2555, 1125, 1151, 2221, 107, 107, 1105, 1175, 1127, 1185, 2091, 8661, 2879, 1895, 27631, 13066, 1224, 1608, 1109, 5884, 1104, 27631, 20702, 1166, 1103, 1736, 1104, 1103, 1480, 107, 107, 1170, 1134, 1553, 1131, 1108, 2752, 1171, 1106, 2001, 10805, 8643, 3875, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSentenceIDs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'reported', 'that', 'her', 'foot', 'had', 'been', 'blue', '\"', '\"', 'and', 'there', 'were', 'no', 'Do', '##pp', '##ler', '##able', 'pulses', 'Color', 'later', 'returned', 'The', 'absence', 'of', 'pulses', 'persisted', 'over', 'the', 'course', 'of', 'the', 'night', '\"', '\"', 'after', 'which', 'point', 'she', 'was', 'referred', 'back', 'to', 'La', '##rg', '##rine', 'Medical', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'nerX', 'nerX', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'nerX', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. \n",
    "\n",
    "\n",
    "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
    "\n",
    "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   5.,    0.,    7.,    0.,    0.,   21.,    0.,    0.,   31.,\n",
       "           0.,   44.,    0.,    0.,   51.,    0.,    0.,   69.,    0.,\n",
       "          85.,    0.,    0.,  108.,    0.,    0.,  128.,    0.,  149.,\n",
       "           0.,    0.,  163.,    0.,    0.,  169.,    0.,    0.,  178.,\n",
       "           0.,  201.,    0.,    0.,  208.,    0.,    0.,  228.,    0.,\n",
       "         228.,    0.,    0.,  224.,    0.,    0.,  222.,    0.,  192.,\n",
       "           0.,    0.,  179.,    0.,    0.,  186.,    0., 4412.]),\n",
       " array([40.        , 40.37096774, 40.74193548, 41.11290323, 41.48387097,\n",
       "        41.85483871, 42.22580645, 42.59677419, 42.96774194, 43.33870968,\n",
       "        43.70967742, 44.08064516, 44.4516129 , 44.82258065, 45.19354839,\n",
       "        45.56451613, 45.93548387, 46.30645161, 46.67741935, 47.0483871 ,\n",
       "        47.41935484, 47.79032258, 48.16129032, 48.53225806, 48.90322581,\n",
       "        49.27419355, 49.64516129, 50.01612903, 50.38709677, 50.75806452,\n",
       "        51.12903226, 51.5       , 51.87096774, 52.24193548, 52.61290323,\n",
       "        52.98387097, 53.35483871, 53.72580645, 54.09677419, 54.46774194,\n",
       "        54.83870968, 55.20967742, 55.58064516, 55.9516129 , 56.32258065,\n",
       "        56.69354839, 57.06451613, 57.43548387, 57.80645161, 58.17741935,\n",
       "        58.5483871 , 58.91935484, 59.29032258, 59.66129032, 60.03225806,\n",
       "        60.40322581, 60.77419355, 61.14516129, 61.51612903, 61.88709677,\n",
       "        62.25806452, 62.62903226, 63.        ]),\n",
       " <a list of 62 Patch objects>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f1c50107eb8>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a lot of tables with value 12+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-do</td>\n",
       "      <td>0</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-du</td>\n",
       "      <td>1</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-f</td>\n",
       "      <td>2</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-m</td>\n",
       "      <td>3</td>\n",
       "      <td>7443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-mo</td>\n",
       "      <td>4</td>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-r</td>\n",
       "      <td>5</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-do</td>\n",
       "      <td>6</td>\n",
       "      <td>3146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-du</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-f</td>\n",
       "      <td>8</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-m</td>\n",
       "      <td>9</td>\n",
       "      <td>3321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-mo</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-r</td>\n",
       "      <td>11</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "      <td>221469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[nerCLS]</td>\n",
       "      <td>13</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[nerPAD]</td>\n",
       "      <td>14</td>\n",
       "      <td>30538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[nerSEP]</td>\n",
       "      <td>15</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nerX</td>\n",
       "      <td>16</td>\n",
       "      <td>183727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag  cat  occurences\n",
       "0       B-do    0        3520\n",
       "1       B-du    1         485\n",
       "2        B-f    2        3171\n",
       "3        B-m    3        7443\n",
       "4       B-mo    4        2664\n",
       "5        B-r    5        1479\n",
       "6       I-do    6        3146\n",
       "7       I-du    7        1020\n",
       "8        I-f    8        1109\n",
       "9        I-m    9        3321\n",
       "10      I-mo   10         109\n",
       "11       I-r   11        1055\n",
       "12         O   12      221469\n",
       "13  [nerCLS]   13        7488\n",
       "14  [nerPAD]   14       30538\n",
       "15  [nerSEP]   15        7488\n",
       "16      nerX   16      183727"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
    "\n",
    "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    0.885908\n",
       "Name: occurences, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_occurences = nerDistribution.loc[nerDistribution.tag == 'O','occurences']\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 13]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **88.5%** is the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
    "\n",
    "In the last step we need to prepare both labels and input for the model, including the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags, tr_sen, val_sen, tr_ner, val_ner = train_test_split(bertSentenceIDs, \n",
    "                                                                                              nerLabels,sentenceTokenList, \n",
    "                                                            nerTokenList,random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(bertMasks, bertSentenceIDs,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_masks[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1132, 15498, 125, 5135, 13335, 8643, 131, 1109, 5351, 1144, 170, 1607, 1104, 17972, 17972, 1335, 1148, 107, 107, 1119, 1108, 1113, 1117, 1313, 13753, 1104, 151, 2101, 3048, 26825, 1134, 1108, 1406, 2338, 4841, 12734, 13064, 3828, 1112, 1218, 1112, 1126, 26825, 7989, 3418, 2279, 1104, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_inputs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 12, 12, 12, 12, 16, 16, 16, 12, 12, 12, 12, 12, 12,  5,  5, 12,\n",
       "       12, 12, 16, 12, 12, 12, 12, 12, 12, 12,  3, 16, 16,  9, 12, 12,  0,\n",
       "        6,  4, 16, 16,  2, 12, 12, 12, 12,  3,  0,  6, 12, 12, 15, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_tags[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'on', 'the', '2', 'of', 'September', 'PA', '##ST', 'S', '##UR', '##GI', '##CA', '##L', 'H', '##IS', '##TO', '##R', '##Y', ':', 'Notable', 'for', 'the', 'above', '\"', '\"', 'as', 'well', 'as', 'de', '##bri', '##de', '##ments', 'of', 'her', 'toe', 'am', '##putation', 'wound', 'site', 'AD', '##MI', '##SS', '##ION', 'ME', '##DI', '##CA', '##TI', '##ON', '##S', ':', 'Cola', '##ce', '100', 'mg', 'b', '.', 'i', '.', 'd', '\"', '\"', 'insulin', '[SEP]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags, dtype=torch.long, device=device)\n",
    "val_tags = torch.tensor(val_tags, dtype=torch.long, device=device)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = BertForTokenClassification.from_pretrained('/root/biobert_pretrain_output_disch_100000', \n",
    "                                                   num_labels=nerDistribution['tag'].count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=7e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report, accuracy_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.6065156456277269\n",
      "Validation loss: 0.11180051602423191\n",
      "Validation Accuracy: 0.9568168444511218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   2%|▏         | 1/50 [02:38<2:09:45, 158.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7033025099075297\n",
      "Recall: 0.6899948159668222\n",
      "Train loss: 0.10102702325907363\n",
      "Validation loss: 0.0713406380576392\n",
      "Validation Accuracy: 0.9690661308092948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   4%|▍         | 2/50 [05:17<2:06:56, 158.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8079893475366178\n",
      "Recall: 0.79884149552396\n",
      "Train loss: 0.07099105923555755\n",
      "Validation loss: 0.05854719690978527\n",
      "Validation Accuracy: 0.9722884740584936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|▌         | 3/50 [07:55<2:04:16, 158.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8318537859007833\n",
      "Recall: 0.8069908814589666\n",
      "Train loss: 0.05682993814419796\n",
      "Validation loss: 0.05107434932142496\n",
      "Validation Accuracy: 0.974739270332532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   8%|▊         | 4/50 [10:34<2:01:38, 158.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8503812779384696\n",
      "Recall: 0.8305084745762712\n",
      "Train loss: 0.04854375500920542\n",
      "Validation loss: 0.047880722830692925\n",
      "Validation Accuracy: 0.9787550706129808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 5/50 [13:13<1:59:00, 158.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.857748344370861\n",
      "Recall: 0.8436685773840542\n",
      "Train loss: 0.0423513617613728\n",
      "Validation loss: 0.046780811001857124\n",
      "Validation Accuracy: 0.9799256936097757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█▏        | 6/50 [15:52<1:56:25, 158.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8641188959660299\n",
      "Recall: 0.8514644351464435\n",
      "Train loss: 0.0377110873494668\n",
      "Validation loss: 0.04509274622735878\n",
      "Validation Accuracy: 0.9814922626201924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 7/50 [18:30<1:53:49, 158.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.865106494872469\n",
      "Recall: 0.844889573703133\n",
      "Train loss: 0.032824336242160246\n",
      "Validation loss: 0.04510757621998588\n",
      "Validation Accuracy: 0.9814202724358975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  16%|█▌        | 8/50 [21:09<1:51:12, 158.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8657505285412262\n",
      "Recall: 0.8495850622406639\n",
      "Train loss: 0.029551892863560063\n",
      "Validation loss: 0.04508782868894438\n",
      "Validation Accuracy: 0.980747320713141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  18%|█▊        | 9/50 [23:47<1:48:21, 158.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8672659968270755\n",
      "Recall: 0.8515057113187954\n",
      "Train loss: 0.026625753940917304\n",
      "Validation loss: 0.0457497660536319\n",
      "Validation Accuracy: 0.9809116461338142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 10/50 [26:25<1:45:35, 158.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8620326487625065\n",
      "Recall: 0.8429454170957775\n",
      "Train loss: 0.023552132470277248\n",
      "Validation loss: 0.04844613062838713\n",
      "Validation Accuracy: 0.9803920648036858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  22%|██▏       | 11/50 [29:03<1:42:46, 158.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8689473684210527\n",
      "Recall: 0.8492798353909465\n",
      "Train loss: 0.021452372026369328\n",
      "Validation loss: 0.04720830350803832\n",
      "Validation Accuracy: 0.9809194711538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  24%|██▍       | 12/50 [31:41<1:40:06, 158.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8701809598741147\n",
      "Recall: 0.8477261113949923\n",
      "Train loss: 0.019539412192700174\n",
      "Validation loss: 0.046832392613093056\n",
      "Validation Accuracy: 0.980503180088141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  26%|██▌       | 13/50 [34:19<1:37:27, 158.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.873231918868428\n",
      "Recall: 0.8651507139079851\n",
      "Train loss: 0.01702951112214776\n",
      "Validation loss: 0.04875812617441019\n",
      "Validation Accuracy: 0.980381109775641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  28%|██▊       | 14/50 [36:57<1:34:51, 158.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8709761842449621\n",
      "Recall: 0.8468193384223919\n",
      "Train loss: 0.015490555129415617\n",
      "Validation loss: 0.05039982652912537\n",
      "Validation Accuracy: 0.9809507712339743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 15/50 [39:34<1:32:07, 157.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8743053717914793\n",
      "Recall: 0.859074362974519\n",
      "Train loss: 0.014277176835499174\n",
      "Validation loss: 0.05310419163045784\n",
      "Validation Accuracy: 0.9806455954527243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  32%|███▏      | 16/50 [42:12<1:29:23, 157.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8689762959103934\n",
      "Recall: 0.8411497730711044\n",
      "Train loss: 0.013359566523706743\n",
      "Validation loss: 0.051852429285645485\n",
      "Validation Accuracy: 0.9811542217548076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  34%|███▍      | 17/50 [44:49<1:26:42, 157.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8677469942498693\n",
      "Recall: 0.8426395939086294\n",
      "Train loss: 0.01202116033472827\n",
      "Validation loss: 0.0547023283628126\n",
      "Validation Accuracy: 0.9818662985777243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  36%|███▌      | 18/50 [47:27<1:24:02, 157.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8783320137239377\n",
      "Recall: 0.8608380755302638\n",
      "Train loss: 0.011117282145881752\n",
      "Validation loss: 0.05547616661836704\n",
      "Validation Accuracy: 0.9815705128205128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|███▊      | 19/50 [50:04<1:21:18, 157.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8736292428198433\n",
      "Recall: 0.8475177304964538\n",
      "Train loss: 0.009988141919252291\n",
      "Validation loss: 0.0588018661364913\n",
      "Validation Accuracy: 0.9822434645432692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 20/50 [52:41<1:18:38, 157.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.882149507847832\n",
      "Recall: 0.8712559117183395\n",
      "Train loss: 0.008963387782831116\n",
      "Validation loss: 0.05927949600542585\n",
      "Validation Accuracy: 0.9830259665464743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  42%|████▏     | 21/50 [55:19<1:16:13, 157.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8745709004489042\n",
      "Recall: 0.8575867426204039\n",
      "Train loss: 0.008218237648550333\n",
      "Validation loss: 0.05938801929975549\n",
      "Validation Accuracy: 0.9830463115985576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  44%|████▍     | 22/50 [57:58<1:13:45, 158.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8787718369507677\n",
      "Recall: 0.8636836628511967\n",
      "Train loss: 0.007563564945972344\n",
      "Validation loss: 0.06422962620854378\n",
      "Validation Accuracy: 0.9832012469951924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  46%|████▌     | 23/50 [1:00:36<1:11:09, 158.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8583120204603581\n",
      "Recall: 0.8169425511197663\n",
      "Train loss: 0.007481826707650135\n",
      "Validation loss: 0.060147714180250965\n",
      "Validation Accuracy: 0.9822325095152243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  48%|████▊     | 24/50 [1:03:14<1:08:24, 157.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8661953390940037\n",
      "Recall: 0.8425878757004585\n",
      "Train loss: 0.006815139272954245\n",
      "Validation loss: 0.06316868060578902\n",
      "Validation Accuracy: 0.9828522511017628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 25/50 [1:05:51<1:05:42, 157.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8674824264514449\n",
      "Recall: 0.839294710327456\n",
      "Train loss: 0.006010877430026301\n",
      "Validation loss: 0.0633628903888166\n",
      "Validation Accuracy: 0.982700445713141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  52%|█████▏    | 26/50 [1:08:28<1:03:00, 157.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8737812911725955\n",
      "Recall: 0.8550799381124291\n",
      "Train loss: 0.005590603961907239\n",
      "Validation loss: 0.06566476565785706\n",
      "Validation Accuracy: 0.9824766501402243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  54%|█████▍    | 27/50 [1:11:06<1:00:23, 157.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8696339215169869\n",
      "Recall: 0.85059247810407\n",
      "Train loss: 0.00530130102633503\n",
      "Validation loss: 0.0672726290455709\n",
      "Validation Accuracy: 0.981845953525641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  56%|█████▌    | 28/50 [1:13:43<57:44, 157.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8674004192872117\n",
      "Recall: 0.8443877551020408\n",
      "Train loss: 0.004700552559318683\n",
      "Validation loss: 0.06776723459673424\n",
      "Validation Accuracy: 0.9823749248798076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  58%|█████▊    | 29/50 [1:16:20<55:06, 157.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8729368614094838\n",
      "Recall: 0.8495665476797553\n",
      "Train loss: 0.00465047990357596\n",
      "Validation loss: 0.06991555518470705\n",
      "Validation Accuracy: 0.9821104392027243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 30/50 [1:18:59<52:36, 157.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.870712401055409\n",
      "Recall: 0.8531540847983454\n",
      "Train loss: 0.004286651985230966\n",
      "Validation loss: 0.0732703961742421\n",
      "Validation Accuracy: 0.9820494040464743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  62%|██████▏   | 31/50 [1:21:38<50:02, 158.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8683867604899661\n",
      "Recall: 0.8409893992932862\n",
      "Train loss: 0.004290022216108296\n",
      "Validation loss: 0.07083937463661034\n",
      "Validation Accuracy: 0.9817254482171475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  64%|██████▍   | 32/50 [1:24:17<47:29, 158.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8708661417322835\n",
      "Recall: 0.8490276356192425\n",
      "Train loss: 0.003937860651099525\n",
      "Validation loss: 0.07485839646930496\n",
      "Validation Accuracy: 0.9814093174078525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  66%|██████▌   | 33/50 [1:26:56<44:55, 158.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8615463652709991\n",
      "Recall: 0.8232695139911634\n",
      "Train loss: 0.003570415703325987\n",
      "Validation loss: 0.07269719972585638\n",
      "Validation Accuracy: 0.9825376852964743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  68%|██████▊   | 34/50 [1:29:34<42:14, 158.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8650338718082334\n",
      "Recall: 0.8375378405650857\n",
      "Train loss: 0.0035258664349419556\n",
      "Validation loss: 0.07334908074699342\n",
      "Validation Accuracy: 0.9821714743589743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 35/50 [1:32:13<39:38, 158.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.872870249017038\n",
      "Recall: 0.8499234303215927\n",
      "Train loss: 0.0031358355014050885\n",
      "Validation loss: 0.07753302343189716\n",
      "Validation Accuracy: 0.9812559470152243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  72%|███████▏  | 36/50 [1:34:52<37:00, 158.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8625518672199171\n",
      "Recall: 0.8315\n",
      "Train loss: 0.0029958581009971296\n",
      "Validation loss: 0.07594458168993394\n",
      "Validation Accuracy: 0.9826785356570512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  74%|███████▍  | 37/50 [1:37:30<34:22, 158.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8730325288562434\n",
      "Recall: 0.8507157464212679\n",
      "Train loss: 0.0032480185095858606\n",
      "Validation loss: 0.07633086177520454\n",
      "Validation Accuracy: 0.9823843149038461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  76%|███████▌  | 38/50 [1:40:08<31:42, 158.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.877341070957531\n",
      "Recall: 0.8594315245478036\n",
      "Train loss: 0.0026070820418698493\n",
      "Validation loss: 0.07584241513783734\n",
      "Validation Accuracy: 0.9835345928485576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  78%|███████▊  | 39/50 [1:42:46<29:01, 158.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.868994486741927\n",
      "Recall: 0.8474142345110087\n",
      "Train loss: 0.002544470572920287\n",
      "Validation loss: 0.08072701818309724\n",
      "Validation Accuracy: 0.9832090720152243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 40/50 [1:45:24<26:22, 158.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8758238861059846\n",
      "Recall: 0.8575116159008777\n",
      "Train loss: 0.002301920767637936\n",
      "Validation loss: 0.0789772750188907\n",
      "Validation Accuracy: 0.9823749248798076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  82%|████████▏ | 41/50 [1:48:02<23:43, 158.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8672659968270755\n",
      "Recall: 0.8515057113187954\n",
      "Train loss: 0.002153098924743162\n",
      "Validation loss: 0.08239562188585599\n",
      "Validation Accuracy: 0.981723883213141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  84%|████████▍ | 42/50 [1:50:41<21:05, 158.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8744088281660536\n",
      "Recall: 0.8533333333333334\n",
      "Train loss: 0.0022403867914583047\n",
      "Validation loss: 0.08083219298472007\n",
      "Validation Accuracy: 0.9834422576121794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  86%|████████▌ | 43/50 [1:53:18<18:26, 158.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8798718633208756\n",
      "Recall: 0.8719576719576719\n",
      "Train loss: 0.0019994461969971783\n",
      "Validation loss: 0.08085960894823074\n",
      "Validation Accuracy: 0.9838804587339743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  88%|████████▊ | 44/50 [1:55:56<15:47, 157.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8729194187582563\n",
      "Recall: 0.8564022809745983\n",
      "Train loss: 0.00214543335421962\n",
      "Validation loss: 0.07817654373745124\n",
      "Validation Accuracy: 0.9838100335536858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 45/50 [1:58:34<13:09, 157.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8718492968957283\n",
      "Recall: 0.8588604286461056\n",
      "Train loss: 0.0018481832219428996\n",
      "Validation loss: 0.08069920330308378\n",
      "Validation Accuracy: 0.984470465244391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  92%|█████████▏| 46/50 [2:01:12<10:31, 158.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8756245069681831\n",
      "Recall: 0.8551617873651772\n",
      "Train loss: 0.001818753399963985\n",
      "Validation loss: 0.08267032463724415\n",
      "Validation Accuracy: 0.9836879632411858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  94%|█████████▍| 47/50 [2:03:50<07:53, 157.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.873394495412844\n",
      "Recall: 0.8504338948443083\n",
      "Train loss: 0.0017962134169426777\n",
      "Validation loss: 0.0816871748926739\n",
      "Validation Accuracy: 0.9841152093349358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  96%|█████████▌| 48/50 [2:06:29<05:16, 158.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8738428987040464\n",
      "Recall: 0.8581818181818182\n",
      "Train loss: 0.0015380799793665875\n",
      "Validation loss: 0.08286839793436229\n",
      "Validation Accuracy: 0.9831480368589743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  98%|█████████▊| 49/50 [2:09:06<02:37, 157.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8807682048546279\n",
      "Recall: 0.8721605916534602\n",
      "Train loss: 0.0013778363394159803\n",
      "Validation loss: 0.08441640669479966\n",
      "Validation Accuracy: 0.982090094150641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 50/50 [2:11:44<00:00, 158.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8732767762460233\n",
      "Recall: 0.8596033402922756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "train_loss = []\n",
    "evaluation_loss = []\n",
    "f1score = []\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    train_loss.append(tr_loss/nb_tr_steps)\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    evaluation_loss.append(eval_loss)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == p_i).idxmax()][0] for p in predictions for p_i in p])\n",
    "    valid_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][0] for l in true_labels for l_i in l for l_ii in l_i])\n",
    "    valid_ids = [nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][1] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    mask = (np.array(valid_ids) < 13)\n",
    "    #print(mask)\n",
    "    pred = np.ma.compressed(np.ma.MaskedArray(pred_tags, mask=~mask))\n",
    "    valid = np.ma.compressed(np.ma.MaskedArray(valid_tags, mask=~mask))\n",
    "    #print(pred.tolist())\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred.tolist(), valid.tolist())))\n",
    "    f1score.append(f1_score(pred.tolist(), valid.tolist()))\n",
    "    print(\"Recall: {}\".format(recall_score(pred.tolist(), valid.tolist())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scipy) (1.16.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Traing Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(f1score)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.title(\"F1 Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BertForTokenClassification.from_pretrained('/root/biobert_pretrain_output_disch_100000', num_labels=nerDistribution['tag'].count())\n",
    "#model = BertForTokenClassification.from_pretrained(\"scibert-basevocab-cased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regexp = re.compile(r'layer\\.[0-11]\\.')\n",
    "for name, param in model1.named_parameters():                \n",
    "    #print (name,regexp.search(name) )\n",
    "    if regexp.search(name):\n",
    "        #print(name)\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=2e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.836097852878661\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|▋         | 1/15 [02:36<36:28, 156.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.836154917405115\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|█▎        | 2/15 [05:12<33:52, 156.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.836018539717977\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 3/15 [07:48<31:14, 156.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.8364907395783194\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|██▋       | 4/15 [10:24<28:38, 156.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.836280938008385\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 5/15 [13:00<26:01, 156.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.8362187039795645\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 6/15 [15:37<23:26, 156.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.8362153005825963\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|████▋     | 7/15 [18:14<20:51, 156.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.835890106680269\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|█████▎    | 8/15 [20:51<18:16, 156.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.836035940884414\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 9/15 [23:28<15:40, 156.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.8364099744371893\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 10/15 [26:04<13:02, 156.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.8365872674643713\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|███████▎  | 11/15 [28:40<10:25, 156.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.8360407894821527\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 12/15 [31:17<07:49, 156.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.835803286159208\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|████████▋ | 13/15 [33:53<05:13, 156.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.8358049098914266\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|█████████▎| 14/15 [36:30<02:36, 156.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n",
      "Train loss: 2.836046408702977\n",
      "Validation loss: 2.8212015529473624\n",
      "Validation Accuracy: 0.055002065805288464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 15/15 [39:07<00:00, 156.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.014627138566018022\n",
      "Recall: 0.007956429078853895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model1.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model1(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model1.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model1.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model1.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model1(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model1(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == p_i).idxmax()][0] for p in predictions for p_i in p])\n",
    "    valid_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][0] for l in true_labels for l_i in l for l_ii in l_i])\n",
    "    valid_ids = [nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][1] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    mask = (np.array(valid_ids) < 13)\n",
    "    #print(mask)\n",
    "    pred = np.ma.compressed(np.ma.MaskedArray(pred_tags, mask=~mask))\n",
    "    valid = np.ma.compressed(np.ma.MaskedArray(valid_tags, mask=~mask))\n",
    "    #print(pred.tolist())\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred.tolist(), valid.tolist())))\n",
    "    print(\"Recall: {}\".format(recall_score(pred.tolist(), valid.tolist())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
