{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Named Entity Recognition Model using  Clinical BERT </center></h1>\n",
    "<h4><center>Final Project W266</center></h4>\n",
    "\n",
    "\n",
    "<h3><center>SUMMARY</center></h3>\n",
    "\n",
    "In this notebook, we will look at implementing various BERT models to understand the significance of domain specific contexts with respect to fine tuning NER task.\n",
    "\n",
    "- The various BERT models used in the notebook are listed below.\n",
    "\n",
    "__BERT:__ \n",
    ">\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\", by Devlin/Chang/Lee/Toutanova, Google AI Language)\n",
    "\n",
    "__BioBERT:__ \n",
    ">A pre-trained biomedical language representation model for biomedical text mining by Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang\n",
    "\n",
    "__SciBERT:__\n",
    ">A Pretrained Language Model for Scientific Text by Iz Beltagy, Kyle Lo, Arman Cohan\n",
    "\n",
    "__ClinicalBert:__\n",
    ">Modeling Clinical Notes and Predicting Hospital Readmission by Kexin Huang, Jaan Altosaar, Rajesh Ranganath\n",
    "\n",
    ">Publicly Available Clinical BERT Embeddings by Emily Alsentzer, John R. Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann, Matthew B. A. McDermott\n",
    "\n",
    "\n",
    "Models used and their corresponding Corpora used:\n",
    "\n",
    "\n",
    "__Base Bert Cased -__  \n",
    "\n",
    ">Wikipedia + BookCorpus\n",
    "\n",
    "__BioBert Cased with PubMed and PMC - __\n",
    "\n",
    ">English Wikipedia, General BooksCorpus, General PubMed Abstracts, PMC Full-text articles\n",
    "\n",
    "__SciBert Cased -__\n",
    "\n",
    ">1.14M papers from Semantic Scholar (Ammar et al., 2018)\n",
    "\n",
    "__biobert_pretrain_output_all_notes_150000__\n",
    "\n",
    ">MIMIC text from all note types on BioBert\n",
    "\n",
    "\n",
    "__biobert_pretrain_output_disch_100000__\n",
    "\n",
    ">MIMIC text from all discharge summaries on BioBert\n",
    "\n",
    "\n",
    "We look at the effect of also fine-tuning BERT layers which are pre-trained with clinical context. \n",
    "\n",
    "\n",
    "### 1. Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "JA25,NNP,O\r\n",
      "Attending:,NNP,O\r\n",
      "SYDNEY,NNP,O\r\n",
      "DUESTERHAUS,NNP,O\r\n",
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "MG85,NNP,O\r\n",
      "EQ681/3978,NNP,O\r\n",
      "Batch:,NNP,O\r\n",
      "37609,CD,O\r\n",
      "Index,NNP,O\r\n",
      "No,NNP,O\r\n",
      "FHOW8875S8,NNP,O\r\n",
      "D:,NNP,O\r\n",
      "6/10,CD,O\r\n",
      "T:,NNP,O\r\n",
      "1/22,CD,O\r\n",
      "[report_end],NN,O\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 'ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the words line-by-line, the labels (POS and NER), and the sentence boundaries. Perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval[gpu] in /opt/conda/lib/python3.6/site-packages (0.0.12)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.16.3)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (2.2.4)\n",
      "Requirement already satisfied: tensorflow-gpu; extra == \"gpu\" in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (5.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.21.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.2.2)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.33.1)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.7.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.0.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.15.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define mddaximal length of input 'sentences' (post tokenization).\n",
    "max_word = 40\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All Models.ipynb', 'scibert_scivocab_cased', 'cuda-repo-ubuntu1604-10-1-local-10.1.168-418.67_1.0-1_amd64.deb', 'ner_tags', 'vocab.txt', 'biobert_pretrain_output_disch_100000', 'biobert_working-pytorch-gpu_v1.ipynb', '.gnupg', 'clibert.bin', 'sentence_boundaries.ipynb', 'scibert_working-pytorch-gpu_v1.ipynb', 'all_bert_models-50.ipynb', 'validation_sentences.csv', 'Baseline_model.ipynb', 'biobert.bin', 'biobert_pretrain_output_all_notes_150000', 'clinicalbert.bin', 'clinicalbert_pytorch-gpu_v1_notes.ipynb', 'attention_decoder.py', 'bert_config.json', 'cuda-repo-ubuntu1604-10-1-local-10.1.105-418.39_1.0-1_amd64.deb', 'validation_ner.csv', 'pytorch_model.bin', 'sentence_model.h5', '.profile', '.config', 'ner_dataset.csv', 'clinicalbert_working-pytorch-gpu_v1.ipynb', 'data', 'convert_to_pytorch_wt.ipynb', '.keras', '.nv', '.bash_history', 'eos.pyc', 'connengine.ipynb', 'answers', 'parser-bert.ipynb', 'bert_working-pytorch-gpu_v1.ipynb', '.pytorch_pretrained_bert', 'best_model.hdf5', 'config.json', '.bashrc', 'validation_pred_ner.csv', '.ipython', 'biobert_v1.0_pubmed_pmc', 'all_bert_models.ipynb', 'weights.tar.gz', 'Inference_notebook.ipynb', 'clinicalbert-pytorch-gpu_20_disch.ipynb', 'RoBERTa_working-pytorch-gpu_v1_11_20.ipynb', '.ssh', 'Untitled.ipynb', 'weights', '.ipynb_checkpoints', 'words.csv', '.local', 'sentences.csv', 'sentence_model.json', '.cache', 'ner.csv']\n",
      "['vocab.txt', 'pytorch_model.bin', 'config.json']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/root\"))\n",
    "print(os.listdir(\"/root/biobert_v1.0_pubmed_pmc\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = '/root/biobert_v1.0_pubmed_pmc/vocab.txt'\n",
    "MODEL = '/root/biobert_v1.0_pubmed_pmc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing <a id=\"preprocess\" />\n",
    "\n",
    "### III.1 BERT Tokenizer<a id=\"tokenizer\" />\n",
    "\n",
    "We first start by defining and exploring the BERT tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/root/biobert_v1.0_pubmed_pmc', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer1 = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's play with the tokenizer. You will see that the tokenizer occasionally splits one word into multiple tokens. Why is that the case? Because the approach of using word pieces reduces the vocabulary size and/or number of unknown words.\n",
    "\n",
    "Here is one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Who', 'was', 'Jim', 'He', '##nson', '?', '[SEP]', 'Jim', 'He', '##nson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n",
      "['[CLS]', 'Who', 'was', 'Jim', 'He', '##nson', '?', '[SEP]', 'Jim', 'He', '##nson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "tokenized_text1 = tokenizer1.tokenize(text)\n",
    "print (tokenized_text)\n",
    "print (tokenized_text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('I\\'ll learn to swim in 12342 years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 178, 112, 1325, 3858, 1106, 11231, 1107, 13414, 23117, 1201, 119]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids([\n",
    "    '[CLS]', 'i', \"'\",'ll', 'learn','to','swim','in','123', '##42', 'years', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faye']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([20958])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now we are ready to use it for our text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2. Extraction<a id=\"extract\"/>\n",
    "\n",
    "\n",
    "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
    "\n",
    "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
    "\n",
    "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
    "\n",
    "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
    "\n",
    "4) Create the mask ids. Mask out all of the padding tokens.\n",
    "\n",
    "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
    "\n",
    "To do this, we first define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['protest'],\n",
       " 'posToken': ['VB'],\n",
       " 'nerToken': ['O'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('protest', 'VB', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['Iraq'],\n",
       " 'posToken': ['NNP'],\n",
       " 'nerToken': ['B-geo'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('Iraq', 'NNP', 'B-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['1000', '##0'],\n",
       " 'posToken': ['CD', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': 2}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('10000', 'CD', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert the text file into appropriate arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "\n",
    "with io.open('ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "word_count = 0\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "for line in text:\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    word, pos, ner = cleanLine.split(',')\n",
    "    \n",
    "    ner = ner[:-1]   # remove DOS token\n",
    "    \n",
    "    # if new sentence starts\n",
    "    if (word_count >= max_word -1):            \n",
    "            \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        \n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "\n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        posTokens = ['[posCLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + word\n",
    "        word_count = 0\n",
    "    \n",
    "    word_count += 1\n",
    "    addDict = addWord(word, pos, ner)\n",
    "\n",
    "    sentenceTokens += addDict['wordToken']\n",
    "    posTokens += addDict['posToken']\n",
    "    nerTokens += addDict['nerToken']\n",
    "\n",
    "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
    "sentLengthList = sentLengthList[2:]\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "posTokenList = posTokenList[2:]\n",
    "nerTokenList = nerTokenList[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "print(sentLengthList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2103, 1115, 1123, 2555, 1125, 1151, 2221, 107, 107, 1105, 1175, 1127, 1185, 2091, 8661, 2879, 1895, 27631, 13066, 1224, 1608, 1109, 5884, 1104, 27631, 20702, 1166, 1103, 1736, 1104, 1103, 1480, 107, 107, 1170, 1134, 1553, 1131, 1108, 2752, 1171, 1106, 2001, 10805, 8643, 3875, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSentenceIDs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'reported', 'that', 'her', 'foot', 'had', 'been', 'blue', '\"', '\"', 'and', 'there', 'were', 'no', 'Do', '##pp', '##ler', '##able', 'pulses', 'Color', 'later', 'returned', 'The', 'absence', 'of', 'pulses', 'persisted', 'over', 'the', 'course', 'of', 'the', 'night', '\"', '\"', 'after', 'which', 'point', 'she', 'was', 'referred', 'back', 'to', 'La', '##rg', '##rine', 'Medical', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'nerX', 'nerX', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'nerX', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. \n",
    "\n",
    "\n",
    "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
    "\n",
    "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   5.,    0.,    7.,    0.,    0.,   21.,    0.,    0.,   31.,\n",
       "           0.,   44.,    0.,    0.,   51.,    0.,    0.,   69.,    0.,\n",
       "          85.,    0.,    0.,  108.,    0.,    0.,  128.,    0.,  149.,\n",
       "           0.,    0.,  163.,    0.,    0.,  169.,    0.,    0.,  178.,\n",
       "           0.,  201.,    0.,    0.,  208.,    0.,    0.,  228.,    0.,\n",
       "         228.,    0.,    0.,  224.,    0.,    0.,  222.,    0.,  192.,\n",
       "           0.,    0.,  179.,    0.,    0.,  186.,    0., 4412.]),\n",
       " array([40.        , 40.37096774, 40.74193548, 41.11290323, 41.48387097,\n",
       "        41.85483871, 42.22580645, 42.59677419, 42.96774194, 43.33870968,\n",
       "        43.70967742, 44.08064516, 44.4516129 , 44.82258065, 45.19354839,\n",
       "        45.56451613, 45.93548387, 46.30645161, 46.67741935, 47.0483871 ,\n",
       "        47.41935484, 47.79032258, 48.16129032, 48.53225806, 48.90322581,\n",
       "        49.27419355, 49.64516129, 50.01612903, 50.38709677, 50.75806452,\n",
       "        51.12903226, 51.5       , 51.87096774, 52.24193548, 52.61290323,\n",
       "        52.98387097, 53.35483871, 53.72580645, 54.09677419, 54.46774194,\n",
       "        54.83870968, 55.20967742, 55.58064516, 55.9516129 , 56.32258065,\n",
       "        56.69354839, 57.06451613, 57.43548387, 57.80645161, 58.17741935,\n",
       "        58.5483871 , 58.91935484, 59.29032258, 59.66129032, 60.03225806,\n",
       "        60.40322581, 60.77419355, 61.14516129, 61.51612903, 61.88709677,\n",
       "        62.25806452, 62.62903226, 63.        ]),\n",
       " <a list of 62 Patch objects>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average sentence length of ~25 (incl. extra tokens!) is roughly expected. It turns out that on these types of corpora an average sentence length of ~20 tends to be seen. The big spike on the right obviously corresponds to all sentences that we had to truncate. \n",
    "\n",
    "Next, we analyze the distribution of ner labels. First, we assign numbers to the labels and look at the overall distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f4805a33f98>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a lot of tables with value 16+... Let's see which labels these label numbers corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-do</td>\n",
       "      <td>0</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-du</td>\n",
       "      <td>1</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-f</td>\n",
       "      <td>2</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-m</td>\n",
       "      <td>3</td>\n",
       "      <td>7443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-mo</td>\n",
       "      <td>4</td>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-r</td>\n",
       "      <td>5</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-do</td>\n",
       "      <td>6</td>\n",
       "      <td>3146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-du</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-f</td>\n",
       "      <td>8</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-m</td>\n",
       "      <td>9</td>\n",
       "      <td>3321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-mo</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-r</td>\n",
       "      <td>11</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "      <td>221469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[nerCLS]</td>\n",
       "      <td>13</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[nerPAD]</td>\n",
       "      <td>14</td>\n",
       "      <td>30538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[nerSEP]</td>\n",
       "      <td>15</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nerX</td>\n",
       "      <td>16</td>\n",
       "      <td>183727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag  cat  occurences\n",
       "0       B-do    0        3520\n",
       "1       B-du    1         485\n",
       "2        B-f    2        3171\n",
       "3        B-m    3        7443\n",
       "4       B-mo    4        2664\n",
       "5        B-r    5        1479\n",
       "6       I-do    6        3146\n",
       "7       I-du    7        1020\n",
       "8        I-f    8        1109\n",
       "9        I-m    9        3321\n",
       "10      I-mo   10         109\n",
       "11       I-r   11        1055\n",
       "12         O   12      221469\n",
       "13  [nerCLS]   13        7488\n",
       "14  [nerPAD]   14       30538\n",
       "15  [nerSEP]   15        7488\n",
       "16      nerX   16      183727"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. 12 corresponds to 'O', and all 'extension' labels (i.e., those that were not part of the original data) occur at 13+. \n",
    "\n",
    "'O' is the most common token - by far.\n",
    "\n",
    "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
    "\n",
    "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    0.885908\n",
       "Name: occurences, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_occurences = nerDistribution.loc[nerDistribution.tag == 'O','occurences']\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 13]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **88.5%** is the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
    "\n",
    "In the last step we need to prepare both labels and input for the model, including the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(bertSentenceIDs, nerLabels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(bertMasks, bertSentenceIDs,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_masks[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1132, 15498, 125, 5135, 13335, 8643, 131, 1109, 5351, 1144, 170, 1607, 1104, 17972, 17972, 1335, 1148, 107, 107, 1119, 1108, 1113, 1117, 1313, 13753, 1104, 151, 2101, 3048, 26825, 1134, 1108, 1406, 2338, 4841, 12734, 13064, 3828, 1112, 1218, 1112, 1126, 26825, 7989, 3418, 2279, 1104, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_inputs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 12, 12, 12, 12, 16, 16, 16, 12, 12, 12, 12, 12, 12,  5,  5, 12,\n",
       "       12, 12, 16, 12, 12, 12, 12, 12, 12, 12,  3, 16, 16,  9, 12, 12,  0,\n",
       "        6,  4, 16, 16,  2, 12, 12, 12, 12,  3,  0,  6, 12, 12, 15, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int8)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_tags[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'on', 'the', '2', 'of', 'September', 'PA', '##ST', 'S', '##UR', '##GI', '##CA', '##L', 'H', '##IS', '##TO', '##R', '##Y', ':', 'Notable', 'for', 'the', 'above', '\"', '\"', 'as', 'well', 'as', 'de', '##bri', '##de', '##ments', 'of', 'her', 'toe', 'am', '##putation', 'wound', 'site', 'AD', '##MI', '##SS', '##ION', 'ME', '##DI', '##CA', '##TI', '##ON', '##S', ':', 'Cola', '##ce', '100', 'mg', 'b', '.', 'i', '.', 'd', '\"', '\"', 'insulin', '[SEP]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags, dtype=torch.long, device=device)\n",
    "val_tags = torch.tensor(val_tags, dtype=torch.long, device=device)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = BertConfig.from_json_file('/root/biobert_v1.0_pubmed_pmc/bert_config.json')\n",
    "model = BertForTokenClassification.from_pretrained('/root/biobert_v1.0_pubmed_pmc', num_labels=nerDistribution['tag'].count())\n",
    "#model = BertForTokenClassification.from_pretrained(\"scibert-basevocab-cased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    print (name)\n",
    "    #if name.startswith('embeddings'):\n",
    "    #    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report, accuracy_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.3433056988387029\n",
      "Validation loss: 0.07227043838550647\n",
      "Validation Accuracy: 0.9731226211939102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   2%|         | 1/50 [02:40<2:10:52, 160.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7883774749292878\n",
      "Recall: 0.7540580423020167\n",
      "Train loss: 0.06523569147168742\n",
      "Validation loss: 0.05670354119502008\n",
      "Validation Accuracy: 0.9810650165264424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   4%|         | 2/50 [05:20<2:08:06, 160.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8488372093023255\n",
      "Recall: 0.83298755186722\n",
      "Train loss: 0.04601038755822521\n",
      "Validation loss: 0.04968642924601833\n",
      "Validation Accuracy: 0.9775061974158654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   6%|         | 3/50 [07:59<2:05:10, 159.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8550573514077163\n",
      "Recall: 0.8282828282828283\n",
      "Train loss: 0.0349171394482255\n",
      "Validation loss: 0.04553612833842635\n",
      "Validation Accuracy: 0.985760028545673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:   8%|         | 4/50 [10:39<2:02:39, 160.00s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8651890482398956\n",
      "Recall: 0.8383021728145528\n",
      "Train loss: 0.027852946954174628\n",
      "Validation loss: 0.04823435051366687\n",
      "Validation Accuracy: 0.9826816656650642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  10%|         | 5/50 [13:19<2:00:04, 160.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8694731268202276\n",
      "Recall: 0.8547631441957314\n",
      "Train loss: 0.022258711411613282\n",
      "Validation loss: 0.05086982483044267\n",
      "Validation Accuracy: 0.9846034905849358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  12%|        | 6/50 [16:00<1:57:25, 160.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8724797067295103\n",
      "Recall: 0.8487009679062659\n",
      "Train loss: 0.018002795653585434\n",
      "Validation loss: 0.05457000791405638\n",
      "Validation Accuracy: 0.984767816005609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  14%|        | 7/50 [18:40<1:54:46, 160.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8703606900156822\n",
      "Recall: 0.8451776649746193\n",
      "Train loss: 0.015268481460121852\n",
      "Validation loss: 0.0558232751985391\n",
      "Validation Accuracy: 0.9861074594350961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  16%|        | 8/50 [21:20<1:52:06, 160.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8735933001831981\n",
      "Recall: 0.8493638676844784\n",
      "Train loss: 0.012574634170468666\n",
      "Validation loss: 0.05608731873023013\n",
      "Validation Accuracy: 0.9831605568910257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  18%|        | 9/50 [24:00<1:49:22, 160.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8728991596638656\n",
      "Recall: 0.8514344262295082\n",
      "Train loss: 0.010396247734624662\n",
      "Validation loss: 0.05712565500289202\n",
      "Validation Accuracy: 0.982414049979968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  20%|        | 10/50 [26:40<1:46:43, 160.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8661661920786955\n",
      "Recall: 0.833582461385152\n",
      "Train loss: 0.009296734199938652\n",
      "Validation loss: 0.06127956478546063\n",
      "Validation Accuracy: 0.978290264423077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  22%|       | 11/50 [29:20<1:44:05, 160.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8777777777777778\n",
      "Recall: 0.8622661122661123\n",
      "Train loss: 0.00810064571982435\n",
      "Validation loss: 0.06266996225652595\n",
      "Validation Accuracy: 0.9791932717347757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  24%|       | 12/50 [31:59<1:41:13, 159.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8790450928381962\n",
      "Recall: 0.8657262277951933\n",
      "Train loss: 0.006870135106587721\n",
      "Validation loss: 0.06385709593693416\n",
      "Validation Accuracy: 0.9767127403846154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  26%|       | 13/50 [34:39<1:38:31, 159.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8789166224110463\n",
      "Recall: 0.8664921465968587\n",
      "Train loss: 0.005974244385664197\n",
      "Validation loss: 0.06931709141160051\n",
      "Validation Accuracy: 0.9799350836338142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  28%|       | 14/50 [37:19<1:35:55, 159.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8719172633253779\n",
      "Recall: 0.8584856396866841\n",
      "Train loss: 0.00545143969169425\n",
      "Validation loss: 0.07057538876930873\n",
      "Validation Accuracy: 0.9796502529046475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  30%|       | 15/50 [40:00<1:33:21, 160.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8673629242819844\n",
      "Recall: 0.8414387031408308\n",
      "Train loss: 0.004946129198348309\n",
      "Validation loss: 0.07038205054899056\n",
      "Validation Accuracy: 0.982883551181891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  32%|      | 16/50 [42:39<1:30:40, 160.02s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8704771893025695\n",
      "Recall: 0.8478038815117467\n",
      "Train loss: 0.004082594060375448\n",
      "Validation loss: 0.07199310410457353\n",
      "Validation Accuracy: 0.9766094501201924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  34%|      | 17/50 [45:18<1:27:50, 159.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8786677240285488\n",
      "Recall: 0.8624805396990141\n",
      "Train loss: 0.0037096196968192277\n",
      "Validation loss: 0.0727227305372556\n",
      "Validation Accuracy: 0.9828632061298076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  36%|      | 18/50 [47:59<1:25:17, 159.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8773038441284887\n",
      "Recall: 0.8578784757981462\n",
      "Train loss: 0.003701528217737294\n",
      "Validation loss: 0.0785955327252547\n",
      "Validation Accuracy: 0.9784608498597757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  38%|      | 19/50 [50:39<1:22:39, 159.97s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8734345856648015\n",
      "Recall: 0.863995782814971\n",
      "Train loss: 0.0037932495703265263\n",
      "Validation loss: 0.07168932460869352\n",
      "Validation Accuracy: 0.9826206305088142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  40%|      | 20/50 [53:19<1:20:03, 160.11s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8737254901960784\n",
      "Recall: 0.8486541391569324\n",
      "Train loss: 0.003330715800915796\n",
      "Validation loss: 0.08057384348164003\n",
      "Validation Accuracy: 0.9787049904847757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  42%|     | 21/50 [55:58<1:17:13, 159.77s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8721052631578948\n",
      "Recall: 0.852366255144033\n",
      "Train loss: 0.0030335548306375045\n",
      "Validation loss: 0.07737051229923964\n",
      "Validation Accuracy: 0.9803842397836539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  44%|     | 22/50 [58:39<1:14:37, 159.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8734345856648015\n",
      "Recall: 0.863995782814971\n",
      "Train loss: 0.002653406651635981\n",
      "Validation loss: 0.08374877281797428\n",
      "Validation Accuracy: 0.9789898212139424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  46%|     | 23/50 [1:01:19<1:12:01, 160.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8765068309670506\n",
      "Recall: 0.8716036228023442\n",
      "Train loss: 0.0021046098648301232\n",
      "Validation loss: 0.08336040431944032\n",
      "Validation Accuracy: 0.9745686848958334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  48%|     | 24/50 [1:03:58<1:09:15, 159.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8773710927063852\n",
      "Recall: 0.8701642819289878\n",
      "Train loss: 0.0022656839539962315\n",
      "Validation loss: 0.08699941914528608\n",
      "Validation Accuracy: 0.9742306440304488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  50%|     | 25/50 [1:06:37<1:06:29, 159.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8692206076618229\n",
      "Recall: 0.8527734577501296\n",
      "Train loss: 0.002172925819930294\n",
      "Validation loss: 0.08526478614658117\n",
      "Validation Accuracy: 0.9702555338541666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  52%|    | 26/50 [1:09:17<1:03:49, 159.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8702088289717156\n",
      "Recall: 0.8541774779449922\n",
      "Train loss: 0.001818462184277778\n",
      "Validation loss: 0.09087553930779298\n",
      "Validation Accuracy: 0.9723416841947116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  54%|    | 27/50 [1:11:57<1:01:12, 159.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.875131717597471\n",
      "Recall: 0.8561855670103092\n",
      "Train loss: 0.002366742314161155\n",
      "Validation loss: 0.08369927170375983\n",
      "Validation Accuracy: 0.9764200846354166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  56%|    | 28/50 [1:14:36<58:31, 159.62s/it]  \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8780872306883868\n",
      "Recall: 0.8569230769230769\n",
      "Train loss: 0.0020548624243235253\n",
      "Validation loss: 0.08138304902240634\n",
      "Validation Accuracy: 0.9763480944511218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  58%|    | 29/50 [1:17:15<55:48, 159.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8768135056713268\n",
      "Recall: 0.8589147286821706\n",
      "Train loss: 0.0018965651480008195\n",
      "Validation loss: 0.0850807895573477\n",
      "Validation Accuracy: 0.9783716446314102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  60%|    | 30/50 [1:19:55<53:07, 159.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8618096966554316\n",
      "Recall: 0.8305847076461769\n",
      "Train loss: 0.0017116242553728415\n",
      "Validation loss: 0.08526683862631519\n",
      "Validation Accuracy: 0.9781275040064102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  62%|   | 31/50 [1:22:34<50:30, 159.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8780745834435335\n",
      "Recall: 0.8623376623376623\n",
      "Train loss: 0.0015742852886980378\n",
      "Validation loss: 0.08572608310108383\n",
      "Validation Accuracy: 0.9766000600961539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  64%|   | 32/50 [1:25:15<47:55, 159.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8714585519412382\n",
      "Recall: 0.8491820040899796\n",
      "Train loss: 0.0015516584501913484\n",
      "Validation loss: 0.08333821517104904\n",
      "Validation Accuracy: 0.9808099208733975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  66%|   | 33/50 [1:27:55<45:16, 159.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.876155268022181\n",
      "Recall: 0.8591403417918178\n",
      "Train loss: 0.0017911334163718967\n",
      "Validation loss: 0.07991833022485177\n",
      "Validation Accuracy: 0.9769161909054488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  68%|   | 34/50 [1:30:35<42:39, 159.98s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8717948717948718\n",
      "Recall: 0.864406779661017\n",
      "Train loss: 0.0013330232071187083\n",
      "Validation loss: 0.08789260173216462\n",
      "Validation Accuracy: 0.9809726812900642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  70%|   | 35/50 [1:33:15<40:00, 160.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8799144156191494\n",
      "Recall: 0.8736059479553904\n",
      "Train loss: 0.0011405024827827348\n",
      "Validation loss: 0.08166894720246394\n",
      "Validation Accuracy: 0.9821824293870192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  72%|  | 36/50 [1:35:56<37:22, 160.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8793608521970705\n",
      "Recall: 0.8694049499736703\n",
      "Train loss: 0.0013289560496240747\n",
      "Validation loss: 0.0988804274238646\n",
      "Validation Accuracy: 0.9803028595753206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  74%|  | 37/50 [1:38:36<34:42, 160.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8730748805098247\n",
      "Recall: 0.8607329842931937\n",
      "Train loss: 0.0014038424167286338\n",
      "Validation loss: 0.09064808472370108\n",
      "Validation Accuracy: 0.9832810621995192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  76%|  | 38/50 [1:41:15<31:59, 159.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8784457862956155\n",
      "Recall: 0.8566308243727598\n",
      "Train loss: 0.0010965594900497488\n",
      "Validation loss: 0.08837486943230033\n",
      "Validation Accuracy: 0.9831683819110576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  78%|  | 39/50 [1:43:54<29:15, 159.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.870507399577167\n",
      "Recall: 0.854253112033195\n",
      "Train loss: 0.0008637342453116035\n",
      "Validation loss: 0.09344810107722878\n",
      "Validation Accuracy: 0.9791744916866988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  80%|  | 40/50 [1:46:33<26:34, 159.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8775834658187599\n",
      "Recall: 0.8633993743482794\n",
      "Train loss: 0.001215559724269085\n",
      "Validation loss: 0.09221034993728001\n",
      "Validation Accuracy: 0.9810931865985576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  82%| | 41/50 [1:49:12<23:53, 159.28s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8729454735194365\n",
      "Recall: 0.8462316641375822\n",
      "Train loss: 0.00149299371213778\n",
      "Validation loss: 0.08866380713880062\n",
      "Validation Accuracy: 0.978351299579327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  84%| | 42/50 [1:51:52<21:16, 159.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8710855949895615\n",
      "Recall: 0.8446356275303644\n",
      "Train loss: 0.001082564667395539\n",
      "Validation loss: 0.08882970393945773\n",
      "Validation Accuracy: 0.9782495743189102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  86%| | 43/50 [1:54:33<18:38, 159.80s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8792735042735043\n",
      "Recall: 0.871822033898305\n",
      "Train loss: 0.0012513681910617577\n",
      "Validation loss: 0.0924201407469809\n",
      "Validation Accuracy: 0.9788677509014424\n",
      "F1-Score: 0.8796569284374163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  88%| | 44/50 [1:57:13<15:59, 159.91s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.8752\n",
      "Train loss: 0.0010390645215468221\n",
      "Validation loss: 0.08731267927214503\n",
      "Validation Accuracy: 0.9754732572115384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  90%| | 45/50 [1:59:54<13:20, 160.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8752941176470589\n",
      "Recall: 0.8501777552056882\n",
      "Train loss: 0.0014627227676307928\n",
      "Validation loss: 0.08938775987674792\n",
      "Validation Accuracy: 0.9789898212139424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  92%|| 46/50 [2:02:33<10:40, 160.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8734412310957815\n",
      "Recall: 0.8604286461055933\n",
      "Train loss: 0.0010337156612903015\n",
      "Validation loss: 0.09251558066656192\n",
      "Validation Accuracy: 0.9775875776241988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  94%|| 47/50 [2:05:14<08:00, 160.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8798283261802575\n",
      "Recall: 0.8760683760683761\n",
      "Train loss: 0.0012295330678222737\n",
      "Validation loss: 0.08804561694463094\n",
      "Validation Accuracy: 0.9767862955729166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  96%|| 48/50 [2:07:55<05:20, 160.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8824306472919418\n",
      "Recall: 0.8657335406946605\n",
      "Train loss: 0.0009409369147123087\n",
      "Validation loss: 0.09522321525340278\n",
      "Validation Accuracy: 0.9781478490584936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  98%|| 49/50 [2:10:36<02:40, 160.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8722002635046113\n",
      "Recall: 0.8535327488396081\n",
      "Train loss: 0.0007491529942328089\n",
      "Validation loss: 0.0920945992693305\n",
      "Validation Accuracy: 0.97625732421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100%|| 50/50 [2:13:17<00:00, 160.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8787958806443095\n",
      "Recall: 0.861729673744174\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "train_loss = []\n",
    "evaluation_loss = []\n",
    "f1score = []\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    train_loss.append(tr_loss/nb_tr_steps)\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    evaluation_loss.append(eval_loss)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == p_i).idxmax()][0] for p in predictions for p_i in p])\n",
    "    valid_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][0] for l in true_labels for l_i in l for l_ii in l_i])\n",
    "    valid_ids = [nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][1] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    mask = (np.array(valid_ids) < 13)\n",
    "    #print(mask)\n",
    "    pred = np.ma.compressed(np.ma.MaskedArray(pred_tags, mask=~mask))\n",
    "    valid = np.ma.compressed(np.ma.MaskedArray(valid_tags, mask=~mask))\n",
    "    #print(pred.tolist())\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred.tolist(), valid.tolist())))\n",
    "    f1score.append(f1_score(pred.tolist(), valid.tolist()))\n",
    "    print(\"Recall: {}\".format(recall_score(pred.tolist(), valid.tolist())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scipy) (1.16.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Traing Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(f1score)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.title(\"F1 Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, '/root/biobert.bin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
