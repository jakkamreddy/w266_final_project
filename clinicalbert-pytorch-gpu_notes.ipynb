{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Named Entity Recognition Model using  Clinical BERT </center></h1>\n",
    "<h4><center>Final Project W266</center></h4>\n",
    "\n",
    "\n",
    "<h3><center>SUMMARY</center></h3>\n",
    "\n",
    "In this notebook we will continue our implmentation of Medical Named Entity Recognition model using Scientific bert (see [\"https://github.com/allenai/scibert\"] \n",
    "\n",
    "\n",
    "`SciBERT` is a `BERT` model trained on scientific text.\n",
    "\n",
    "* `SciBERT` is trained on papers from the corpus of [semanticscholar.org](https://semanticscholar.org). Corpus size is 1.14M papers, 3.1B tokens. We use the full text of the papers in training, not just abstracts.\n",
    "\n",
    "* `SciBERT` has its own vocabulary (`scivocab`) that's built to best match the training corpus. We trained cased and uncased versions. We also include models trained on the original BERT vocabulary (`basevocab`) for comparison.\n",
    "\n",
    "We look at the effect of also fine-tuning BERT layers which are pre-trained with clinical context. \n",
    "\n",
    "\n",
    "## II. Setup & Strategy\n",
    "\n",
    "### II.1. Data<a id=\"data\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "JA25,NNP,O\r\n",
      "Attending:,NNP,O\r\n",
      "SYDNEY,NNP,O\r\n",
      "DUESTERHAUS,NNP,O\r\n",
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "MG85,NNP,O\r\n",
      "EQ681/3978,NNP,O\r\n",
      "Batch:,NNP,O\r\n",
      "37609,CD,O\r\n",
      "Index,NNP,O\r\n",
      "No,NNP,O\r\n",
      "FHOW8875S8,NNP,O\r\n",
      "D:,NNP,O\r\n",
      "6/10,CD,O\r\n",
      "T:,NNP,O\r\n",
      "1/22,CD,O\r\n",
      "[report_end],NN,O\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 'ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. Getting Started<a id=\"start\" />\n",
    "\n",
    "We start with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval[gpu] in /opt/conda/lib/python3.6/site-packages (0.0.12)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (2.2.4)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.16.3)\n",
      "Requirement already satisfied: tensorflow-gpu; extra == \"gpu\" in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.0.8)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.3.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (5.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (2.9.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.7.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.33.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.2.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.21.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.8.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (41.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.15.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define mddaximal length of input 'sentences' (post tokenization).\n",
    "max_word = 40\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific bert Model \n",
    "\n",
    "#### Lets look at the model weights and the vocab file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All Models.ipynb', 'scibert_scivocab_cased', 'cuda-repo-ubuntu1604-10-1-local-10.1.168-418.67_1.0-1_amd64.deb', 'ner_tags', 'vocab.txt', 'biobert_pretrain_output_disch_100000', 'biobert_working-pytorch-gpu_v1.ipynb', '.gnupg', 'clibert.bin', 'sentence_boundaries.ipynb', 'all_bert_models-50.ipynb', 'validation_sentences.csv', 'Baseline_model.ipynb', 'biobert.bin', 'scibert-pytorch-gpu.ipynb', 'biobert_pretrain_output_all_notes_150000', 'clinicalbert.bin', 'attention_decoder.py', 'bert_config.json', 'cuda-repo-ubuntu1604-10-1-local-10.1.105-418.39_1.0-1_amd64.deb', 'clinicalbert-pytorch-gpu_notes.ipynb', 'validation_ner.csv', 'pytorch_model.bin', 'sentence_model.h5', '.profile', '.config', 'ner_dataset.csv', 'clinicalbert_working-pytorch-gpu_v1.ipynb', 'data', 'convert_to_pytorch_wt.ipynb', '.keras', '.nv', '.bash_history', 'eos.pyc', 'connengine.ipynb', 'answers', 'parser-bert.ipynb', 'bert_working-pytorch-gpu_v1.ipynb', '.pytorch_pretrained_bert', 'best_model.hdf5', 'config.json', '.bashrc', 'validation_pred_ner.csv', '.ipython', 'biobert_v1.0_pubmed_pmc', 'clinicalbert_pytorch-gpu_disch.ipynb', 'all_bert_models.ipynb', 'weights.tar.gz', 'Inference_notebook.ipynb', 'RoBERTa_working-pytorch-gpu_v1_11_20.ipynb', '.ssh', 'Untitled.ipynb', 'weights', '.ipynb_checkpoints', 'words.csv', '.local', 'sentences.csv', 'sentence_model.json', '.cache', 'ner.csv']\n",
      "['vocab.txt', 'bert_config.json', 'pytorch_model.bin']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/root\"))\n",
    "print(os.listdir(\"/root/biobert_pretrain_output_all_notes_150000\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = '/root/biobert_pretrain_output_all_notes_150000/vocab.txt'\n",
    "MODEL = '/root/biobert_pretrain_output_all_notes_150000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing <a id=\"preprocess\" />\n",
    "\n",
    "### III.1 BERT Tokenizer<a id=\"tokenizer\" />\n",
    "\n",
    "We first start by defining and exploring the BERT tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/root/biobert_pretrain_output_disch_100000', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Who', 'was', 'Jim', 'He', '##nson', '?', '[SEP]', 'Jim', 'He', '##nson', 'was', 'a', 'puppet', '##eer', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print (tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('I\\'ll learn to swim in 12342 years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[146, 112, 1325, 3858, 1106, 11231, 1107, 13414, 23117, 1201, 119]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['I', \"'\", 'll', 'learn', 'to', 'swim', 'in', '123', '##42', 'years', '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faye']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([20958])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now we are ready to use it for our text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2. Extraction<a id=\"extract\"/>\n",
    "\n",
    "\n",
    "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
    "\n",
    "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
    "\n",
    "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
    "\n",
    "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
    "\n",
    "4) Create the mask ids. Mask out all of the padding tokens.\n",
    "\n",
    "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
    "\n",
    "To do this, we first define a helper function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = list(str(tokenLength))\n",
    "    \n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['protest'],\n",
       " 'posToken': ['VB'],\n",
       " 'nerToken': ['O'],\n",
       " 'tokenLength': ['1']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('protest', 'VB', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['Iraq'],\n",
       " 'posToken': ['NNP'],\n",
       " 'nerToken': ['B-geo'],\n",
       " 'tokenLength': ['1']}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('Iraq', 'NNP', 'B-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['1000', '##0'],\n",
       " 'posToken': ['CD', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': ['2']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('10000', 'CD', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert the text file into appropriate arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "\n",
    "with io.open('ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "word_count = 0\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "sentenceTokenLen = []\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "nerTokenLen = ['1']\n",
    "\n",
    "for line in text:\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    word, pos, ner = cleanLine.split(',')\n",
    "    \n",
    "    ner = ner[:-1]   # remove DOS token\n",
    "    \n",
    "    # if new sentence starts\n",
    "    if (word_count >= max_word -1):            \n",
    "            \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        \n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "\n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "        \n",
    "        sentenceTokenLen.append(nerTokenLen)\n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        posTokens = ['[posCLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + word\n",
    "        word_count = 0\n",
    "    \n",
    "    word_count += 1\n",
    "    addDict = addWord(word, pos, ner)\n",
    "\n",
    "    sentenceTokens += addDict['wordToken']\n",
    "    posTokens += addDict['posToken']\n",
    "    nerTokens += addDict['nerToken']\n",
    "    nerTokenLen += addDict['tokenLength']\n",
    "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
    "sentLengthList = sentLengthList[2:]\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "posTokenList = posTokenList[2:]\n",
    "nerTokenList = nerTokenList[2:]\n",
    "nerTokenLen = nerTokenLen[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenLen[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "print(sentLengthList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2103, 1115, 1123, 2555, 1125, 1151, 2221, 107, 107, 1105, 1175, 1127, 1185, 2091, 8661, 2879, 1895, 27631, 13066, 1224, 1608, 1109, 5884, 1104, 27631, 20702, 1166, 1103, 1736, 1104, 1103, 1480, 107, 107, 1170, 1134, 1553, 1131, 1108, 2752, 1171, 1106, 2001, 10805, 8643, 3875, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSentenceIDs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'reported', 'that', 'her', 'foot', 'had', 'been', 'blue', '\"', '\"', 'and', 'there', 'were', 'no', 'Do', '##pp', '##ler', '##able', 'pulses', 'Color', 'later', 'returned', 'The', 'absence', 'of', 'pulses', 'persisted', 'over', 'the', 'course', 'of', 'the', 'night', '\"', '\"', 'after', 'which', 'point', 'she', 'was', 'referred', 'back', 'to', 'La', '##rg', '##rine', 'Medical', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'nerX', 'nerX', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'nerX', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. \n",
    "\n",
    "\n",
    "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
    "\n",
    "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   5.,    0.,    7.,    0.,    0.,   21.,    0.,    0.,   31.,\n",
       "           0.,   44.,    0.,    0.,   51.,    0.,    0.,   69.,    0.,\n",
       "          85.,    0.,    0.,  108.,    0.,    0.,  128.,    0.,  149.,\n",
       "           0.,    0.,  163.,    0.,    0.,  169.,    0.,    0.,  178.,\n",
       "           0.,  201.,    0.,    0.,  208.,    0.,    0.,  228.,    0.,\n",
       "         228.,    0.,    0.,  224.,    0.,    0.,  222.,    0.,  192.,\n",
       "           0.,    0.,  179.,    0.,    0.,  186.,    0., 4412.]),\n",
       " array([40.        , 40.37096774, 40.74193548, 41.11290323, 41.48387097,\n",
       "        41.85483871, 42.22580645, 42.59677419, 42.96774194, 43.33870968,\n",
       "        43.70967742, 44.08064516, 44.4516129 , 44.82258065, 45.19354839,\n",
       "        45.56451613, 45.93548387, 46.30645161, 46.67741935, 47.0483871 ,\n",
       "        47.41935484, 47.79032258, 48.16129032, 48.53225806, 48.90322581,\n",
       "        49.27419355, 49.64516129, 50.01612903, 50.38709677, 50.75806452,\n",
       "        51.12903226, 51.5       , 51.87096774, 52.24193548, 52.61290323,\n",
       "        52.98387097, 53.35483871, 53.72580645, 54.09677419, 54.46774194,\n",
       "        54.83870968, 55.20967742, 55.58064516, 55.9516129 , 56.32258065,\n",
       "        56.69354839, 57.06451613, 57.43548387, 57.80645161, 58.17741935,\n",
       "        58.5483871 , 58.91935484, 59.29032258, 59.66129032, 60.03225806,\n",
       "        60.40322581, 60.77419355, 61.14516129, 61.51612903, 61.88709677,\n",
       "        62.25806452, 62.62903226, 63.        ]),\n",
       " <a list of 62 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fbc0e63b390>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEICAYAAACqMQjAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAUiklEQVR4nO3df5Bdd3nf8fenVihGAsuuE5VYTuUkDh3HKsRWjVtKZxU7RoAb0xlKYQiWiYM7xaTQUcEiDXULJFV/AIVJ6lbFquyUonrAFNc2cVRhlWGmBv8IsTAOtQYESDU2IFtE4IaKPv3jfoWvN/cr7V3t3ruY92vmzr3nOd9zzqO7q/vZ82PPpqqQJGmUPzftBiRJS5chIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEhTlmRfkoun3Yc0iiEhSeoyJKQFlOTMJDcn+UaSbyX5nSQ/k+STbfqbST6UZGUb/3vATwH/LcnhJG+b7r9Aeqp4Ww5pYSQ5CbgP+CTwm8D3gXXA14GzgE8BzwE+CtxXVW9py+0Dfq2q/vsU2paOadm0G5CeRi4AfhJ4a1UdabVPt+e97fkbSd4LXDvp5qT5MCSkhXMm8JWhgAAgySrg/cCLgWczOMz72OTbk8bnOQlp4XwN+Kkks3/4+m2ggLVV9RzgV4AMzfeYr5YsQ0JaOJ8FHga2JFme5JlJXsRg7+EwcCjJGcBbZy33CPDTk21VmhtDQlogVfV94G8BPwt8FdgP/F3gnwHnAYeA24CbZy36z4HfTPJ4kn80uY6l4/PqJklSl3sSkqQuQ0KS1GVISJK6DAlJUtfT7pfpTj/99FqzZs28lv3Od77D8uXLF7ahBWBf47Gv8djXeJZqX3Bivd17773frKof/zMzqupp9Tj//PNrvu688855L7uY7Gs89jUe+xrPUu2r6sR6A+6pEZ+pHm6SJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1Pe1uyyFpaVuz+bY5jdu09ghXDI3dt+Xli9WSjsE9CUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSuo4bEknOTHJnki8keSDJm1v9tCQ7kzzUnk9t9ST5QJK9Se5Pct7Quja28Q8l2ThUPz/JnrbMB5LkWNuQJE3GXPYkjgCbquoc4ELg6iTnAJuBXVV1NrCrTQO8FDi7Pa4CroPBBz5wLfBC4ALg2qEP/euANwwtt6HVe9uQJE3AcUOiqh6uqvva6z8BHgTOAC4DbmjDbgBe0V5fBtxYA3cBK5M8F3gJsLOqDlbVY8BOYEOb95yququqCrhx1rpGbUOSNAEZfC7PcXCyBvgUcC7w1apa2eoBHquqlUluBbZU1afbvF3ANcAM8MyqenervwN4Atjdxl/c6i8GrqmqS5M8PmobI/q6isFeC6tWrTp/x44dY74NA4cPH2bFihXzWnYx2dd47Gs8k+5rz4FDcxq36mR45Iknp9eeccoidTSepfp1hBPrbf369fdW1brZ9WVzXUGSFcBHgbdU1bfbaQMAqqqSzD1t5uFY26iqrcBWgHXr1tXMzMy8trF7927mu+xisq/x2Nd4Jt3XFZtvm9O4TWuP8J49T35E7XvtzCJ1NJ6l+nWExeltTlc3JfkxBgHxoaq6uZUfaYeKaM+PtvoB4MyhxVe32rHqq0fUj7UNSdIEzOXqpgDXAw9W1XuHZt0CHL1CaSPw8aH65e0qpwuBQ1X1MHAHcEmSU9sJ60uAO9q8bye5sG3r8lnrGrUNSdIEzOVw04uA1wF7knyu1X4D2ALclORK4CvAq9q824GXAXuB7wKvB6iqg0neBdzdxr2zqg62128EtgMnA59oD46xDUnSBBw3JNoJ6HRmXzRifAFXd9a1Ddg2on4Pg5Phs+vfGrUNSdJk+BvXkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkrjnfBVaStPjWzPEuuaNs37B8ATsZcE9CktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVLXcUMiybYkjyb5/FDtnyY5kORz7fGyoXlvT7I3yReTvGSovqHV9ibZPFQ/K8lnWv2/JHlGq//5Nr23zV+zUP9oSdLczGVPYjuwYUT9fVX1gva4HSDJOcCrgZ9vy/zbJCclOQn4XeClwDnAa9pYgH/R1vWzwGPAla1+JfBYq7+vjZMkTdBxQ6KqPgUcnOP6LgN2VNWfVtWXgb3ABe2xt6q+VFXfA3YAlyUJ8IvAR9ryNwCvGFrXDe31R4CL2nhJ0oScyDmJNyW5vx2OOrXVzgC+NjRmf6v16n8BeLyqjsyqP2Vdbf6hNl6SNCHL5rncdcC7gGrP7wF+daGaGleSq4CrAFatWsXu3bvntZ7Dhw/Pe9nFZF/jsa/xTLqvTWuPHH8QsOrkp45dKu/dYr9fc31/RlmM3uYVElX1yNHXSf4DcGubPACcOTR0davRqX8LWJlkWdtbGB5/dF37kywDTmnjR/WzFdgKsG7dupqZmZnPP4vdu3cz32UXk32Nx77GM+m+rth825zGbVp7hPfsefIjat9rZxapo/Es9vs11/dnlO0bli94b/M63JTkuUOTfxs4euXTLcCr25VJZwFnA58F7gbOblcyPYPBye1bqqqAO4FXtuU3Ah8fWtfG9vqVwCfbeEnShBx3TyLJh4EZ4PQk+4FrgZkkL2BwuGkf8PcAquqBJDcBXwCOAFdX1ffbet4E3AGcBGyrqgfaJq4BdiR5N/CHwPWtfj3we0n2Mjhx/uoT/tdKksZy3JCoqteMKF8/onZ0/G8BvzWifjtw+4j6lxhc/TS7/n+Av3O8/iRJi8ffuJYkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jpuSCTZluTRJJ8fqp2WZGeSh9rzqa2eJB9IsjfJ/UnOG1pmYxv/UJKNQ/Xzk+xpy3wgSY61DUnS5MxlT2I7sGFWbTOwq6rOBna1aYCXAme3x1XAdTD4wAeuBV4IXABcO/Shfx3whqHlNhxnG5KkCTluSFTVp4CDs8qXATe01zcArxiq31gDdwErkzwXeAmws6oOVtVjwE5gQ5v3nKq6q6oKuHHWukZtQ5I0IRl8Nh9nULIGuLWqzm3Tj1fVyvY6wGNVtTLJrcCWqvp0m7cLuAaYAZ5ZVe9u9XcATwC72/iLW/3FwDVVdWlvG53+rmKw58KqVavO37FjxzzeCjh8+DArVqyY17KLyb7GY1/jmXRfew4cmtO4VSfDI088Ob32jFMWqaPxLPb7Ndf3Z5SzTjlp3r2tX7/+3qpaN7u+bN7dNFVVSY6fNIu4jaraCmwFWLduXc3MzMxrO7t372a+yy4m+xqPfY1n0n1dsfm2OY3btPYI79nz5EfUvtfOLFJH41ns92uu788o2zcsX/De5nt10yPtUBHt+dFWPwCcOTRudasdq756RP1Y25AkTch8Q+IW4OgVShuBjw/VL29XOV0IHKqqh4E7gEuSnNpOWF8C3NHmfTvJhe2Q0uWz1jVqG5KkCTnu4aYkH2ZwTuH0JPsZXKW0BbgpyZXAV4BXteG3Ay8D9gLfBV4PUFUHk7wLuLuNe2dVHT0Z/kYGV1CdDHyiPTjGNiRJE3LckKiq13RmXTRibAFXd9azDdg2on4PcO6I+rdGbUOSNDn+xrUkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSeoyJCRJXYaEJKnLkJAkdRkSkqQuQ0KS1GVISJK6DAlJUtcJhUSSfUn2JPlcknta7bQkO5M81J5PbfUk+UCSvUnuT3Le0Ho2tvEPJdk4VD+/rX9vWzYn0q8kaTwLsSexvqpeUFXr2vRmYFdVnQ3satMALwXObo+rgOtgECrAtcALgQuAa48GSxvzhqHlNixAv5KkOVqMw02XATe01zcArxiq31gDdwErkzwXeAmws6oOVtVjwE5gQ5v3nKq6q6oKuHFoXZKkCcjg83eeCydfBh4DCvj3VbU1yeNVtbLND/BYVa1Mciuwpao+3ebtAq4BZoBnVtW7W/0dwBPA7jb+4lZ/MXBNVV06oo+rGOydsGrVqvN37Ngxr3/P4cOHWbFixbyWXUz2NR77Gs+k+9pz4NCcxq06GR554snptWecskgdjWex36+5vj+jnHXKSfPubf369fcOHRH6gWXz7mbgb1TVgSQ/AexM8sfDM6uqksw/heaoqrYCWwHWrVtXMzMz81rP7t27me+yi8m+xmNf45l0X1dsvm1O4zatPcJ79jz5EbXvtTOL1NF4Fvv9muv7M8r2DcsXvLcTOtxUVQfa86PAxxicU3ikHSqiPT/ahh8AzhxafHWrHau+ekRdkjQh8w6JJMuTPPvoa+AS4PPALcDRK5Q2Ah9vr28BLm9XOV0IHKqqh4E7gEuSnNpOWF8C3NHmfTvJhe2w1eVD65IkTcCJHG5aBXysXZW6DPjPVfX7Se4GbkpyJfAV4FVt/O3Ay4C9wHeB1wNU1cEk7wLubuPeWVUH2+s3AtuBk4FPtIckaULmHRJV9SXg+SPq3wIuGlEv4OrOurYB20bU7wHOnW+PkqQT429cS5K6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldJ/pHhyTpaWvNiD8AtGntkTn9YaB9W16+GC1NnHsSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSpy5CQJHUZEpKkLkNCktRlSEiSugwJSVKXISFJ6jIkJEldhoQkqcuQkCR1GRKSpC5DQpLUZUhIkroMCUlSlyEhSepaNu0GNH9rNt82r+X2bXn5AnciLW3z/b/yw7bNxeCehCSpy5CQJHUZEpKkriV/TiLJBuD9wEnAB6tqy2Jta8+BQ1wx4eP8czluuWntkXn3tdCG+x2nrxM5DzLusd2jff2wnXvxHJOWoiUdEklOAn4X+CVgP3B3kluq6gvT7UzjerqcxJN+1CzpkAAuAPZW1ZcAkuwALgOWXEj4Ifj0shhfz6W0R3ii/H7/0ZGqmnYPXUleCWyoql9r068DXlhVb5o17irgqjb5POCL89zk6cA357nsYrKv8djXeOxrPEu1Lzix3v5SVf347OJS35OYk6raCmw90fUkuaeq1i1ASwvKvsZjX+Oxr/Es1b5gcXpb6lc3HQDOHJpe3WqSpAlY6iFxN3B2krOSPAN4NXDLlHuSpB8ZS/pwU1UdSfIm4A4Gl8Buq6oHFnGTJ3zIapHY13jsazz2NZ6l2hcsQm9L+sS1JGm6lvrhJknSFBkSkqQuQ6JJsiHJF5PsTbJ52v0AJDkzyZ1JvpDkgSRvnnZPw5KclOQPk9w67V6OSrIyyUeS/HGSB5P8tWn3BJDkH7av4eeTfDjJM6fUx7Ykjyb5/FDttCQ7kzzUnk9dIn39q/Z1vD/Jx5KsXAp9Dc3blKSSnL5U+kry6+09eyDJv1yIbRkSPOX2Hy8FzgFek+Sc6XYFwBFgU1WdA1wIXL1E+jrqzcCD025ilvcDv19Vfxl4PkugvyRnAP8AWFdV5zK4COPVU2pnO7BhVm0zsKuqzgZ2telJ286f7WsncG5V/RXgfwFvn3RTjO6LJGcClwBfnXRDzXZm9ZVkPYM7Ujy/qn4e+NcLsSFDYuAHt/+oqu8BR2//MVVV9XBV3dde/wmDD7wzptvVQJLVwMuBD067l6OSnAL8TeB6gKr6XlU9Pt2ufmAZcHKSZcCzgP89jSaq6lPAwVnly4Ab2usbgFdMtClG91VVf1BVR9rkXQx+T2rqfTXvA94GTOXKn05ffx/YUlV/2sY8uhDbMiQGzgC+NjS9nyXyYXxUkjXALwCfmW4nP/BvGPwn+X/TbmTIWcA3gP/YDoN9MMnyaTdVVQcY/FT3VeBh4FBV/cF0u3qKVVX1cHv9dWDVNJvp+FXgE9NuAiDJZcCBqvqjafcyy88BL07ymST/I8lfXYiVGhI/BJKsAD4KvKWqvr0E+rkUeLSq7p12L7MsA84DrquqXwC+w3QOnTxFO8Z/GYMQ+0lgeZJfmW5Xo9XgmvgldV18kn/M4NDrh5ZAL88CfgP4J9PuZYRlwGkMDk2/FbgpSU50pYbEwJK9/UeSH2MQEB+qqpun3U/zIuCXk+xjcGjuF5P8p+m2BAz2APdX1dG9rY8wCI1puxj4clV9o6r+L3Az8Nen3NOwR5I8F6A9L8hhioWQ5ArgUuC1tTR+qetnGIT9H7Xv/9XAfUn+4lS7GtgP3FwDn2Wwl3/CJ9UNiYElefuP9lPA9cCDVfXeafdzVFW9vapWV9UaBu/VJ6tq6j8ZV9XXga8leV4rXcTSuK38V4ELkzyrfU0vYgmcUB9yC7Cxvd4IfHyKvfxA+4NjbwN+uaq+O+1+AKpqT1X9RFWtad//+4Hz2vfetP1XYD1Akp8DnsEC3K3WkGBw+w/g6O0/HgRuWuTbf8zVi4DXMfhJ/XPt8bJpN7XE/TrwoST3Ay8AfnvK/dD2bD4C3AfsYfD/biq3dkjyYeB/As9Lsj/JlcAW4JeSPMRgr2fR/vrjmH39DvBsYGf73v93S6Svqev0tQ346XZZ7A5g40LsfXlbDklSl3sSkqQuQ0KS1GVISJK6DAlJUpchIUnqMiQkSV2GhCSp6/8DIUeJBxVJ4uEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a lot of tables with value 12+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-do</td>\n",
       "      <td>0</td>\n",
       "      <td>3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-du</td>\n",
       "      <td>1</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-f</td>\n",
       "      <td>2</td>\n",
       "      <td>3171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-m</td>\n",
       "      <td>3</td>\n",
       "      <td>7443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-mo</td>\n",
       "      <td>4</td>\n",
       "      <td>2664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-r</td>\n",
       "      <td>5</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-do</td>\n",
       "      <td>6</td>\n",
       "      <td>3146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-du</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-f</td>\n",
       "      <td>8</td>\n",
       "      <td>1109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-m</td>\n",
       "      <td>9</td>\n",
       "      <td>3321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-mo</td>\n",
       "      <td>10</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-r</td>\n",
       "      <td>11</td>\n",
       "      <td>1055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "      <td>221469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[nerCLS]</td>\n",
       "      <td>13</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[nerPAD]</td>\n",
       "      <td>14</td>\n",
       "      <td>30538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[nerSEP]</td>\n",
       "      <td>15</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nerX</td>\n",
       "      <td>16</td>\n",
       "      <td>183727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag  cat  occurences\n",
       "0       B-do    0        3520\n",
       "1       B-du    1         485\n",
       "2        B-f    2        3171\n",
       "3        B-m    3        7443\n",
       "4       B-mo    4        2664\n",
       "5        B-r    5        1479\n",
       "6       I-do    6        3146\n",
       "7       I-du    7        1020\n",
       "8        I-f    8        1109\n",
       "9        I-m    9        3321\n",
       "10      I-mo   10         109\n",
       "11       I-r   11        1055\n",
       "12         O   12      221469\n",
       "13  [nerCLS]   13        7488\n",
       "14  [nerPAD]   14       30538\n",
       "15  [nerSEP]   15        7488\n",
       "16      nerX   16      183727"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nerDistribution1 = nerDistribution[['tag', 'cat']]\n",
    "\n",
    "nerDistribution1.to_csv('ner_tags', sep='\\t', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
    "\n",
    "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    0.885908\n",
       "Name: occurences, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_occurences = nerDistribution.loc[nerDistribution.tag == 'O','occurences']\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 13]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **88.5%** is the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
    "\n",
    "In the last step we need to prepare both labels and input for the model, including the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags, tr_sen, val_sen, tr_ner, val_ner = train_test_split(bertSentenceIDs, \n",
    "                                                                                              nerLabels,sentenceTokenList, \n",
    "                                                            nerTokenList,random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(bertMasks, bertSentenceIDs,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_masks[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1132, 15498, 125, 5135, 13335, 8643, 131, 1109, 5351, 1144, 170, 1607, 1104, 17972, 17972, 1335, 1148, 107, 107, 1119, 1108, 1113, 1117, 1313, 13753, 1104, 151, 2101, 3048, 26825, 1134, 1108, 1406, 2338, 4841, 12734, 13064, 3828, 1112, 1218, 1112, 1126, 26825, 7989, 3418, 2279, 1104, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_inputs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 12, 12, 12, 12, 16, 16, 16, 12, 12, 12, 12, 12, 12,  5,  5, 12,\n",
       "       12, 12, 16, 12, 12, 12, 12, 12, 12, 12,  3, 16, 16,  9, 12, 12,  0,\n",
       "        6,  4, 16, 16,  2, 12, 12, 12, 12,  3,  0,  6, 12, 12, 15, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_tags[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'on', 'the', '2', 'of', 'September', 'PA', '##ST', 'S', '##UR', '##GI', '##CA', '##L', 'H', '##IS', '##TO', '##R', '##Y', ':', 'Notable', 'for', 'the', 'above', '\"', '\"', 'as', 'well', 'as', 'de', '##bri', '##de', '##ments', 'of', 'her', 'toe', 'am', '##putation', 'wound', 'site', 'AD', '##MI', '##SS', '##ION', 'ME', '##DI', '##CA', '##TI', '##ON', '##S', ':', 'Cola', '##ce', '100', 'mg', 'b', '.', 'i', '.', 'd', '\"', '\"', 'insulin', '[SEP]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags, dtype=torch.long, device=device)\n",
    "val_tags = torch.tensor(val_tags, dtype=torch.long, device=device)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = BertConfig.from_json_file('/root/biobert_v1.0_pubmed_pmc/bert_config.json')\n",
    "model = BertForTokenClassification.from_pretrained('/root/biobert_pretrain_output_all_notes_150000', num_labels=nerDistribution['tag'].count())\n",
    "#model = BertForTokenClassification.from_pretrained(\"scibert-basevocab-cased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=9e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report, accuracy_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5329372774438835\n",
      "Validation loss: 0.1116071396196882\n",
      "Validation Accuracy: 0.9505364833733975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   2%|▏         | 1/50 [02:39<2:10:15, 159.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.6829527349973447\n",
      "Recall: 0.6732984293193718\n",
      "Train loss: 0.09884966984038104\n",
      "Validation loss: 0.07049883032838504\n",
      "Validation Accuracy: 0.9623960837339743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   4%|▍         | 2/50 [05:18<2:07:29, 159.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8015936254980081\n",
      "Recall: 0.7904662126767942\n",
      "Train loss: 0.06837365868108533\n",
      "Validation loss: 0.059890006513645254\n",
      "Validation Accuracy: 0.9653038611778846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|▌         | 3/50 [07:57<2:04:45, 159.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8160123171670516\n",
      "Recall: 0.7790298873101421\n",
      "Train loss: 0.05454288859149856\n",
      "Validation loss: 0.05418618357119461\n",
      "Validation Accuracy: 0.9688094701522436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   8%|▊         | 4/50 [10:36<2:01:55, 159.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8351933558266287\n",
      "Recall: 0.8057085628442664\n",
      "Train loss: 0.04594379069363054\n",
      "Validation loss: 0.05256184213794768\n",
      "Validation Accuracy: 0.9675793770032052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 5/50 [13:14<1:59:11, 158.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8386765837394203\n",
      "Recall: 0.8002936857562408\n",
      "Train loss: 0.039504831912816986\n",
      "Validation loss: 0.049474261701107025\n",
      "Validation Accuracy: 0.9684150891426282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█▏        | 6/50 [15:52<1:56:22, 158.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8468328141225338\n",
      "Recall: 0.8171342685370742\n",
      "Train loss: 0.0346392253722766\n",
      "Validation loss: 0.04734084623244902\n",
      "Validation Accuracy: 0.9724105443709936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 7/50 [18:31<1:53:36, 158.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8527334554015171\n",
      "Recall: 0.8286731062531775\n",
      "Train loss: 0.03019396778001887\n",
      "Validation loss: 0.04891204841745397\n",
      "Validation Accuracy: 0.9728096203926282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  16%|█▌        | 8/50 [21:09<1:50:55, 158.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8531073446327683\n",
      "Recall: 0.8150147203140333\n",
      "Train loss: 0.026362630880715863\n",
      "Validation loss: 0.048070016239459314\n",
      "Validation Accuracy: 0.9742118639823718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  18%|█▊        | 9/50 [23:48<1:48:25, 158.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8574380165289255\n",
      "Recall: 0.8234126984126984\n",
      "Train loss: 0.023357025744896648\n",
      "Validation loss: 0.04997502360492945\n",
      "Validation Accuracy: 0.9765797150440706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 10/50 [26:27<1:45:53, 158.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.873328088119591\n",
      "Recall: 0.8507920286152274\n",
      "Train loss: 0.02030710187206548\n",
      "Validation loss: 0.05142081071001788\n",
      "Validation Accuracy: 0.976276104266827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  22%|██▏       | 11/50 [29:07<1:43:20, 158.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.861219195849546\n",
      "Recall: 0.8304152076038019\n",
      "Train loss: 0.01794143325110712\n",
      "Validation loss: 0.055139682022854686\n",
      "Validation Accuracy: 0.975246331630609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  24%|██▍       | 12/50 [31:46<1:40:44, 159.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.875629806417396\n",
      "Recall: 0.8621409921671018\n",
      "Train loss: 0.01649444164284527\n",
      "Validation loss: 0.05188576062209904\n",
      "Validation Accuracy: 0.9770273061899039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  26%|██▌       | 13/50 [34:25<1:38:08, 159.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8644593895499224\n",
      "Recall: 0.8313432835820895\n",
      "Train loss: 0.014539752973208283\n",
      "Validation loss: 0.054147288436070085\n",
      "Validation Accuracy: 0.9786830804286858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  28%|██▊       | 14/50 [37:04<1:35:20, 158.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8635416666666665\n",
      "Recall: 0.8356854838709677\n",
      "Train loss: 0.012658921242537091\n",
      "Validation loss: 0.05855422195357581\n",
      "Validation Accuracy: 0.9785109299879808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 15/50 [39:42<1:32:37, 158.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8620689655172414\n",
      "Recall: 0.8251231527093597\n",
      "Train loss: 0.011266474188327507\n",
      "Validation loss: 0.059544629883021116\n",
      "Validation Accuracy: 0.9791416266025642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  32%|███▏      | 16/50 [42:20<1:29:53, 158.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8575891694871128\n",
      "Recall: 0.8297229219143577\n",
      "Train loss: 0.010129194938957304\n",
      "Validation loss: 0.0640675153893729\n",
      "Validation Accuracy: 0.979823968349359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  34%|███▍      | 17/50 [45:00<1:27:23, 158.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8613554061045008\n",
      "Recall: 0.8283582089552238\n",
      "Train loss: 0.00915669287517402\n",
      "Validation loss: 0.0652083073121806\n",
      "Validation Accuracy: 0.9793043870192308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  36%|███▌      | 18/50 [47:39<1:24:45, 158.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8636363636363636\n",
      "Recall: 0.8382352941176471\n",
      "Train loss: 0.008354635824233082\n",
      "Validation loss: 0.06419836450368166\n",
      "Validation Accuracy: 0.980537610176282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|███▊      | 19/50 [50:18<1:22:10, 159.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8636481241914618\n",
      "Recall: 0.8307615729218517\n",
      "Train loss: 0.007592006550629522\n",
      "Validation loss: 0.0679460046812892\n",
      "Validation Accuracy: 0.9814813075921475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 20/50 [52:57<1:19:27, 158.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8673173305196518\n",
      "Recall: 0.8496124031007752\n",
      "Train loss: 0.007049274866158028\n",
      "Validation loss: 0.06730370875447989\n",
      "Validation Accuracy: 0.9813592372796475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  42%|████▏     | 21/50 [55:36<1:16:47, 158.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8674192701496457\n",
      "Recall: 0.8458781362007168\n",
      "Train loss: 0.006204256152853334\n",
      "Validation loss: 0.06880783281909923\n",
      "Validation Accuracy: 0.9805329151642628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  44%|████▍     | 22/50 [58:14<1:14:02, 158.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8647519582245431\n",
      "Recall: 0.8389057750759878\n",
      "Train loss: 0.006173072955229042\n",
      "Validation loss: 0.06887704211597641\n",
      "Validation Accuracy: 0.9798036232972757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  46%|████▌     | 23/50 [1:00:53<1:11:29, 158.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8606344253770151\n",
      "Recall: 0.8316582914572864\n",
      "Train loss: 0.005243332839049002\n",
      "Validation loss: 0.0672803920848916\n",
      "Validation Accuracy: 0.979038336338141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  48%|████▊     | 24/50 [1:03:32<1:08:53, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8622881355932204\n",
      "Recall: 0.8479166666666667\n",
      "Train loss: 0.00501765433014194\n",
      "Validation loss: 0.06883403775282204\n",
      "Validation Accuracy: 0.9808490459735576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 25/50 [1:06:11<1:06:16, 159.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.861643475977947\n",
      "Recall: 0.8402457757296466\n",
      "Train loss: 0.004487394028198707\n",
      "Validation loss: 0.0724570363915215\n",
      "Validation Accuracy: 0.9810728415464743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  52%|█████▏    | 26/50 [1:08:51<1:03:37, 159.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8692690594707886\n",
      "Recall: 0.845996940336563\n",
      "Train loss: 0.004309551234487267\n",
      "Validation loss: 0.07283997784058253\n",
      "Validation Accuracy: 0.9773418719951924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  54%|█████▍    | 27/50 [1:11:30<1:01:00, 159.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8602428313097391\n",
      "Recall: 0.826302729528536\n",
      "Train loss: 0.004031962398671373\n",
      "Validation loss: 0.07425153053676088\n",
      "Validation Accuracy: 0.9795688726963142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  56%|█████▌    | 28/50 [1:14:08<58:15, 158.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.869496440812022\n",
      "Recall: 0.8513164687661332\n",
      "Train loss: 0.003505277926719116\n",
      "Validation loss: 0.07874281797558069\n",
      "Validation Accuracy: 0.9791118915264424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  58%|█████▊    | 29/50 [1:16:47<55:33, 158.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.858179932590096\n",
      "Recall: 0.8270864567716142\n",
      "Train loss: 0.0035633877714515458\n",
      "Validation loss: 0.07909134263172746\n",
      "Validation Accuracy: 0.9795688726963142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 30/50 [1:19:25<52:50, 158.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.868062827225131\n",
      "Recall: 0.8441955193482689\n",
      "Train loss: 0.0030035309316160078\n",
      "Validation loss: 0.07759743416681886\n",
      "Validation Accuracy: 0.977260491786859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  62%|██████▏   | 31/50 [1:22:03<50:11, 158.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8656795346377578\n",
      "Recall: 0.8499480789200415\n",
      "Train loss: 0.0029272693854875825\n",
      "Validation loss: 0.07946492351281147\n",
      "Validation Accuracy: 0.9795579176682692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  64%|██████▍   | 32/50 [1:24:41<47:30, 158.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8695884553714591\n",
      "Recall: 0.8626723223753977\n",
      "Train loss: 0.002999891318856425\n",
      "Validation loss: 0.07923977527146538\n",
      "Validation Accuracy: 0.9797222430889424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  66%|██████▌   | 33/50 [1:27:19<44:51, 158.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8538860103626943\n",
      "Recall: 0.8223552894211577\n",
      "Train loss: 0.0024182535496223676\n",
      "Validation loss: 0.0847116019576788\n",
      "Validation Accuracy: 0.9811041416266025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  68%|██████▊   | 34/50 [1:29:58<42:13, 158.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8655529037390612\n",
      "Recall: 0.852219321148825\n",
      "Train loss: 0.00228179884526627\n",
      "Validation loss: 0.08347428791845839\n",
      "Validation Accuracy: 0.980049328926282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 35/50 [1:32:36<39:34, 158.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8669640514300708\n",
      "Recall: 0.8450127877237852\n",
      "Train loss: 0.0022516386007991624\n",
      "Validation loss: 0.08217262911299865\n",
      "Validation Accuracy: 0.9795375726161858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  72%|███████▏  | 36/50 [1:35:15<36:58, 158.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8697478991596639\n",
      "Recall: 0.8483606557377049\n",
      "Train loss: 0.002359837469627189\n",
      "Validation loss: 0.07905345348020394\n",
      "Validation Accuracy: 0.9779522235576924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  74%|███████▍  | 37/50 [1:37:53<34:18, 158.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8575122834238429\n",
      "Recall: 0.8244654400795625\n",
      "Train loss: 0.0020406514329513563\n",
      "Validation loss: 0.08167463603119056\n",
      "Validation Accuracy: 0.9767847305689102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  76%|███████▌  | 38/50 [1:40:32<31:44, 158.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8677664310028803\n",
      "Recall: 0.8441161487519103\n",
      "Train loss: 0.0018541450543694367\n",
      "Validation loss: 0.08749524612600605\n",
      "Validation Accuracy: 0.9770977313701924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  78%|███████▊  | 39/50 [1:43:12<29:08, 158.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.872948650079407\n",
      "Recall: 0.8579604578563996\n",
      "Train loss: 0.0018289561203216926\n",
      "Validation loss: 0.08763675546894471\n",
      "Validation Accuracy: 0.9782996544471154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 40/50 [1:45:51<26:31, 159.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8634361233480178\n",
      "Recall: 0.8317523714428358\n",
      "Train loss: 0.0017373467408235393\n",
      "Validation loss: 0.08575857756659389\n",
      "Validation Accuracy: 0.9781744541266025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  82%|████████▏ | 41/50 [1:48:31<23:53, 159.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8755980861244018\n",
      "Recall: 0.8641133263378804\n",
      "Train loss: 0.0016445162583247899\n",
      "Validation loss: 0.08671434448721509\n",
      "Validation Accuracy: 0.9770883413461539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  84%|████████▍ | 42/50 [1:51:11<21:15, 159.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8628168278024563\n",
      "Recall: 0.8376458650431253\n",
      "Train loss: 0.0014467673286960032\n",
      "Validation loss: 0.08961654625212152\n",
      "Validation Accuracy: 0.9765906700721154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  86%|████████▌ | 43/50 [1:53:49<18:32, 158.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.873157894736842\n",
      "Recall: 0.8533950617283951\n",
      "Train loss: 0.0016822764504537035\n",
      "Validation loss: 0.08432206899548571\n",
      "Validation Accuracy: 0.976143078926282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  88%|████████▊ | 44/50 [1:56:27<15:52, 158.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.868766404199475\n",
      "Recall: 0.8469805527123848\n",
      "Train loss: 0.0014121919064745319\n",
      "Validation loss: 0.09031143179163337\n",
      "Validation Accuracy: 0.9754513471554488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 45/50 [1:59:05<13:13, 158.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8684967320261439\n",
      "Recall: 0.8435754189944135\n",
      "Train loss: 0.0012746002519297992\n",
      "Validation loss: 0.09288939973339438\n",
      "Validation Accuracy: 0.9780429937900642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  92%|█████████▏| 46/50 [2:01:45<10:35, 158.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8634338138925295\n",
      "Recall: 0.8407350689127105\n",
      "Train loss: 0.0013531302073978714\n",
      "Validation loss: 0.08669297971452276\n",
      "Validation Accuracy: 0.9792543068910257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  94%|█████████▍| 47/50 [2:04:24<07:57, 159.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8723516949152542\n",
      "Recall: 0.8578125\n",
      "Train loss: 0.0010897871806354966\n",
      "Validation loss: 0.08846070291474462\n",
      "Validation Accuracy: 0.9785531850961539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  96%|█████████▌| 48/50 [2:07:03<05:18, 159.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8659630606860158\n",
      "Recall: 0.8485005170630817\n",
      "Train loss: 0.0010064974864746191\n",
      "Validation loss: 0.09497794120882948\n",
      "Validation Accuracy: 0.9788990509815706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  98%|█████████▊| 49/50 [2:09:42<02:39, 159.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8696109358569927\n",
      "Recall: 0.8490759753593429\n",
      "Train loss: 0.0009334777936411655\n",
      "Validation loss: 0.09345860189447801\n",
      "Validation Accuracy: 0.9781181139823718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 50/50 [2:12:21<00:00, 159.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8693834900731452\n",
      "Recall: 0.8438133874239351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "train_loss = []\n",
    "evaluation_loss = []\n",
    "f1score = []\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    train_loss.append(tr_loss/nb_tr_steps)\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    evaluation_loss.append(eval_loss)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == p_i).idxmax()][0] for p in predictions for p_i in p])\n",
    "    valid_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][0] for l in true_labels for l_i in l for l_ii in l_i])\n",
    "    valid_ids = [nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][1] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    mask = (np.array(valid_ids) < 13)\n",
    "    #print(mask)\n",
    "    pred = np.ma.compressed(np.ma.MaskedArray(pred_tags, mask=~mask))\n",
    "    valid = np.ma.compressed(np.ma.MaskedArray(valid_tags, mask=~mask))\n",
    "    #print(pred.tolist())\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred.tolist(), valid.tolist())))\n",
    "    f1score.append(f1_score(pred.tolist(), valid.tolist()))\n",
    "    print(\"Recall: {}\".format(recall_score(pred.tolist(), valid.tolist())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scipy) (1.16.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Traing Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(f1score)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.title(\"F1 Curve\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "with open('sentences.csv', 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "     wr.writerow(sentenceTokenList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ner.csv', 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "     wr.writerow(nerTokenList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_sentences.csv', 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "     wr.writerow(val_sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_ner.csv', 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "     wr.writerow(val_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_pred_ner.csv', 'w', newline='') as myfile:\n",
    "     wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "     wr.writerow(pred_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BertForTokenClassification.from_pretrained('/root/biobert_pretrain_output_all_notes_150000', num_labels=nerDistribution['tag'].count())\n",
    "#model = BertForTokenClassification.from_pretrained(\"scibert-basevocab-cased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "regexp = re.compile(r'layer\\.[0-7]\\.')\n",
    "for name, param in model1.named_parameters():                \n",
    "    #print (name,regexp.search(name) )\n",
    "    if regexp.search(name):\n",
    "        #print(name)\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1)\n",
       "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.861893290027058\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   7%|▋         | 1/15 [02:30<35:06, 150.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861677095223377\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  13%|█▎        | 2/15 [05:01<32:36, 150.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.8616827562521983\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 3/15 [07:31<30:05, 150.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861751904419813\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  27%|██▋       | 4/15 [10:01<27:34, 150.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.8616034329220015\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  33%|███▎      | 5/15 [12:31<25:00, 150.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861428565888608\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 6/15 [15:01<22:31, 150.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861783991492755\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  47%|████▋     | 7/15 [17:31<20:01, 150.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861643307581897\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  53%|█████▎    | 8/15 [20:01<17:30, 150.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861455733177221\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 9/15 [22:31<14:59, 149.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.8614733049654846\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  67%|██████▋   | 10/15 [25:02<12:31, 150.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.862215961890198\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  73%|███████▎  | 11/15 [27:31<10:00, 150.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.862082519802437\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 12/15 [30:01<07:30, 150.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861621467988073\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  87%|████████▋ | 13/15 [32:32<05:00, 150.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.861316069607486\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  93%|█████████▎| 14/15 [35:02<02:30, 150.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n",
      "Train loss: 2.8615032846893746\n",
      "Validation loss: 2.8695632417996726\n",
      "Validation Accuracy: 0.06788674379006411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 15/15 [37:33<00:00, 150.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.005109006826690157\n",
      "Recall: 0.0027819080051801046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model1.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model1(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model1.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model1.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    # VALIDATION on validation set\n",
    "    model1.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model1(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model1(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == p_i).idxmax()][0] for p in predictions for p_i in p])\n",
    "    valid_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][0] for l in true_labels for l_i in l for l_ii in l_i])\n",
    "    valid_ids = [nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][1] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    mask = (np.array(valid_ids) < 13)\n",
    "    #print(mask)\n",
    "    pred = np.ma.compressed(np.ma.MaskedArray(pred_tags, mask=~mask))\n",
    "    valid = np.ma.compressed(np.ma.MaskedArray(valid_tags, mask=~mask))\n",
    "    #print(pred.tolist())\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred.tolist(), valid.tolist())))\n",
    "    print(\"Recall: {}\".format(recall_score(pred.tolist(), valid.tolist())))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
