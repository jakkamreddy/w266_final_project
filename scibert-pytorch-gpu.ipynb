{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Named Entity Recognition Model using  Clinical BERT </center></h1>\n",
    "<h4><center>Final Project W266</center></h4>\n",
    "\n",
    "\n",
    "<h3><center>SUMMARY</center></h3>\n",
    "\n",
    "In this notebook, we will look at implementing various BERT models to understand the significance of domain specific contexts with respect to fine tuning NER task.\n",
    "\n",
    "- The various BERT models used in the notebook are listed below.\n",
    "\n",
    "__BERT:__ \n",
    ">\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\", by Devlin/Chang/Lee/Toutanova, Google AI Language)\n",
    "\n",
    "__BioBERT:__ \n",
    ">A pre-trained biomedical language representation model for biomedical text mining by Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, Jaewoo Kang\n",
    "\n",
    "__SciBERT:__\n",
    ">A Pretrained Language Model for Scientific Text by Iz Beltagy, Kyle Lo, Arman Cohan\n",
    "\n",
    "__ClinicalBert:__\n",
    ">Modeling Clinical Notes and Predicting Hospital Readmission by Kexin Huang, Jaan Altosaar, Rajesh Ranganath\n",
    "\n",
    ">Publicly Available Clinical BERT Embeddings by Emily Alsentzer, John R. Murphy, Willie Boag, Wei-Hung Weng, Di Jin, Tristan Naumann, Matthew B. A. McDermott\n",
    "\n",
    "\n",
    "Models used and their corresponding Corpora used:\n",
    "\n",
    "\n",
    "__Base Bert Cased -__  \n",
    "\n",
    ">Wikipedia + BookCorpus\n",
    "\n",
    "__BioBert Cased with PubMed and PMC - __\n",
    "\n",
    ">English Wikipedia, General BooksCorpus, General PubMed Abstracts, PMC Full-text articles\n",
    "\n",
    "__SciBert Cased -__\n",
    "\n",
    ">1.14M papers from Semantic Scholar (Ammar et al., 2018)\n",
    "\n",
    "__biobert_pretrain_output_all_notes_150000__\n",
    "\n",
    ">MIMIC text from all note types on BioBert\n",
    "\n",
    "\n",
    "__biobert_pretrain_output_disch_100000__\n",
    "\n",
    ">MIMIC text from all discharge summaries on BioBert\n",
    "\n",
    "\n",
    "We look at the effect of also fine-tuning BERT layers which are pre-trained with clinical context. \n",
    "\n",
    "\n",
    "### 1. Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "JA25,NNP,O\r\n",
      "Attending:,NNP,O\r\n",
      "SYDNEY,NNP,O\r\n",
      "DUESTERHAUS,NNP,O\r\n",
      "\",\",\",\",O\r\n",
      "M.D,NNP,O\r\n",
      "MG85,NNP,O\r\n",
      "EQ681/3978,NNP,O\r\n",
      "Batch:,NNP,O\r\n",
      "37609,CD,O\r\n",
      "Index,NNP,O\r\n",
      "No,NNP,O\r\n",
      "FHOW8875S8,NNP,O\r\n",
      "D:,NNP,O\r\n",
      "6/10,CD,O\r\n",
      "T:,NNP,O\r\n",
      "1/22,CD,O\r\n",
      "[report_end],NN,O\r\n"
     ]
    }
   ],
   "source": [
    "!tail -20 'ner_dataset.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scintific  BERT\n",
    "\n",
    "\n",
    "We start with some imports, adding the data and bert path, and then completing all imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval[gpu] in /opt/conda/lib/python3.6/site-packages (0.0.12)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.16.3)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (2.2.4)\n",
      "Requirement already satisfied: tensorflow-gpu; extra == \"gpu\" in /opt/conda/lib/python3.6/site-packages (from seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.12.0)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (2.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (5.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.8.0)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.21.1)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.8.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (1.13.0)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.2.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.33.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (41.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (0.15.4)\n",
      "Requirement already satisfied: mock>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow-gpu; extra == \"gpu\"->seqeval[gpu]) (3.0.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "from time import time\n",
    "import io\n",
    "import re\n",
    "from csv import reader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.python.keras.layers import Lambda\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "from tensorflow.keras.backend import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, TimeDistributed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define mddaximal length of input 'sentences' (post tokenization).\n",
    "max_word = 40\n",
    "max_length = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['All Models.ipynb', 'scibert_scivocab_cased', 'cuda-repo-ubuntu1604-10-1-local-10.1.168-418.67_1.0-1_amd64.deb', 'ner_tags', 'vocab.txt', 'biobert_pretrain_output_disch_100000', 'biobert_working-pytorch-gpu_v1.ipynb', '.gnupg', 'clibert.bin', 'sentence_boundaries.ipynb', 'all_bert_models-50.ipynb', 'validation_sentences.csv', 'Baseline_model.ipynb', 'biobert.bin', 'scibert-pytorch-gpu.ipynb', 'biobert_pretrain_output_all_notes_150000', 'clinicalbert.bin', 'attention_decoder.py', 'bert_config.json', 'cuda-repo-ubuntu1604-10-1-local-10.1.105-418.39_1.0-1_amd64.deb', 'clinicalbert-pytorch-gpu_notes.ipynb', 'validation_ner.csv', 'pytorch_model.bin', 'sentence_model.h5', '.profile', '.config', 'ner_dataset.csv', 'clinicalbert_working-pytorch-gpu_v1.ipynb', 'data', 'convert_to_pytorch_wt.ipynb', '.keras', '.nv', '.bash_history', 'eos.pyc', 'connengine.ipynb', 'answers', 'parser-bert.ipynb', 'bert_working-pytorch-gpu_v1.ipynb', '.pytorch_pretrained_bert', 'best_model.hdf5', 'config.json', '.bashrc', 'validation_pred_ner.csv', '.ipython', 'biobert_v1.0_pubmed_pmc', 'clinicalbert_pytorch-gpu_disch.ipynb', 'all_bert_models.ipynb', 'weights.tar.gz', 'Inference_notebook.ipynb', 'RoBERTa_working-pytorch-gpu_v1_11_20.ipynb', '.ssh', 'Untitled.ipynb', 'weights', '.ipynb_checkpoints', 'words.csv', '.local', 'sentences.csv', 'sentence_model.json', '.cache', 'ner.csv']\n",
      "['vocab.txt', 'bert_config.json', 'pytorch_model.bin', 'weights.tar.gz', '.ipynb_checkpoints']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"/root\"))\n",
    "print(os.listdir(\"/root/scibert_scivocab_cased\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = '/root/scibert_scivocab_cased/vocab.txt'\n",
    "MODEL = '/root/scibert_scivocab_cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P100-PCIE-16GB'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Data Preprocessing <a id=\"preprocess\" />\n",
    "\n",
    "### III.1 BERT Tokenizer<a id=\"tokenizer\" />\n",
    "\n",
    "We first start by defining and exploring the BERT tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('/root/scibert_scivocab_cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer1 = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'Wh', '##o', 'was', 'Jim', 'Hen', '##son', '?', '[SEP]', 'Jim', 'Hen', '##son', 'was', 'a', 'pup', '##pet', '##ee', '##r', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = \"[CLS] Who was Jim Henson ? [SEP] Jim Henson was a puppeteer [SEP]\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "print (tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " \"'\",\n",
       " 'll',\n",
       " 'learn',\n",
       " 'to',\n",
       " 'sw',\n",
       " '##im',\n",
       " 'in',\n",
       " '123',\n",
       " '##42',\n",
       " 'years',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('I\\'ll learn to swim in 12342 years.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the \"I'll\" phrase and the number '12342' got split. This already highlights an area one needs to address: splitting of tokens will need to be accounted for in the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[179, 2517, 8939, 4298, 146, 2170, 162, 124, 14796, 5593, 1314, 211]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['I',\n",
    " \"'\",\n",
    " 'll',\n",
    " 'learn',\n",
    " 'to',\n",
    " 'sw',\n",
    " '##im',\n",
    " 'in',\n",
    " '123',\n",
    " '##42',\n",
    " 'years',\n",
    " '.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['locom']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([20958])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Now we are ready to use it for our text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.2. Extraction<a id=\"extract\"/>\n",
    "\n",
    "\n",
    "We have seen above how the data set looks. We can now turn to the pre-processing and creating the input for BERT. Specifically, we need to:\n",
    "\n",
    "1) Tokenize the sentences. Note again that one word can be split into multiple tokens, and we need to insert custom labels when that happens to make sure we don't mess up the alignment. We choose a new 'nerX' label here.\n",
    "\n",
    "2) Create BERT tokens and add [CLS], [PAD], etc.\n",
    "\n",
    "3) Convert these tokens into ids, also via the tokenizer. These qill create the sentence_ids.\n",
    "\n",
    "4) Create the mask ids. Mask out all of the padding tokens.\n",
    "\n",
    "5) Create the sequence ids. In our case, they are all '0' as we do not compare or even have multiple sentences in one example.\n",
    "\n",
    "To do this, we first define a helper function:\n",
    "\n",
    "*This piece has been reused from the course notebook and modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addWord(word, pos, ner):\n",
    "    \"\"\"\n",
    "    Convert a word into a word token and add supplied NER and POS labels. Note that the word can be  \n",
    "    tokenized to two or more tokens. Correspondingly, we add - for now - custom 'X' tokens to the labels in order to \n",
    "    maintain the 1:1 mappings between word tokens and labels.\n",
    "    \n",
    "    arguments: word, pos label, ner label\n",
    "    returns: dictionary with tokens and labels\n",
    "    \"\"\"\n",
    "    # the dataset contains various '\"\"\"' combinations which we choose to truncate to '\"', etc. \n",
    "    if word == '\"\"\"\"':\n",
    "        word = '\"'\n",
    "    elif word == '``':\n",
    "        word = '`'\n",
    "        \n",
    "    tokens = tokenizer.tokenize(word)\n",
    "    tokenLength = len(tokens)      # find number of tokens corresponfing to word to later add 'X' tokens to labels\n",
    "    \n",
    "    addDict = dict()\n",
    "    \n",
    "    addDict['wordToken'] = tokens\n",
    "    addDict['posToken'] = [pos] + ['posX'] * (tokenLength - 1)\n",
    "    addDict['nerToken'] = [ner] + ['nerX'] * (tokenLength - 1)\n",
    "    addDict['tokenLength'] = tokenLength\n",
    "    \n",
    "    \n",
    "    return addDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['prote', '##st'],\n",
       " 'posToken': ['VB', 'posX'],\n",
       " 'nerToken': ['O', 'nerX'],\n",
       " 'tokenLength': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('protest', 'VB', 'O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['Ir', '##a', '##q'],\n",
       " 'posToken': ['NNP', 'posX', 'posX'],\n",
       " 'nerToken': ['B-geo', 'nerX', 'nerX'],\n",
       " 'tokenLength': 3}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('Iraq', 'NNP', 'B-geo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wordToken': ['10000'],\n",
       " 'posToken': ['CD'],\n",
       " 'nerToken': ['O'],\n",
       " 'tokenLength': 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addWord('10000', 'CD', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to convert the text file into appropriate arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read the file line by line and construct sentences. A sentence end is marked by the word 'sentence' in the next row.\n",
    "You need to take care of that. Also, you need to cap sentence length using max_length. Sentences which are shorter than \n",
    "max_length need to be padded. Also, we choose to end all sentences with a [SEP] token, padded or not. \n",
    "\"\"\"\n",
    "\n",
    "with io.open('ner_dataset.csv', 'r', encoding='utf-8', errors='ignore') as train:\n",
    "    text = train.readlines()\n",
    "\n",
    "\n",
    "# lists for sentences, tokens, labels, etc.  \n",
    "sentenceList = []\n",
    "word_count = 0\n",
    "sentenceTokenList = []\n",
    "posTokenList = []\n",
    "nerTokenList = []\n",
    "sentLengthList = []\n",
    "\n",
    "# lists for BERT input\n",
    "bertSentenceIDs = []\n",
    "bertMasks = []\n",
    "bertSequenceIDs = []\n",
    "\n",
    "sentence = ''\n",
    "\n",
    "# always start with [CLS] tokens\n",
    "sentenceTokens = ['[CLS]']\n",
    "posTokens = ['[posCLS]']\n",
    "nerTokens = ['[nerCLS]']\n",
    "\n",
    "for line in text:\n",
    "    \n",
    "    cleanLine = re.sub(r'(?!(([^\"]*\"){2})*[^\"]*$),', '', line)  # deal with '\"10,000\"' and convert them to '10000' \n",
    "\n",
    "    word, pos, ner = cleanLine.split(',')\n",
    "    \n",
    "    ner = ner[:-1]   # remove DOS token\n",
    "    \n",
    "    # if new sentence starts\n",
    "    if (word_count >= max_word -1):            \n",
    "            \n",
    "        sentenceLength = min(max_length -1, len(sentenceTokens))\n",
    "        sentLengthList.append(sentenceLength)\n",
    "        \n",
    "                    \n",
    "        # Create space for at least a final '[SEP]' token\n",
    "        if sentenceLength >= max_length - 1: \n",
    "            sentenceTokens = sentenceTokens[:max_length - 2]\n",
    "            posTokens = posTokens[:max_length - 2]\n",
    "            nerTokens = nerTokens[:max_length - 2]\n",
    "\n",
    "        # add a ['SEP'] token and padding\n",
    "        \n",
    "        sentenceTokens += ['[SEP]'] + ['[PAD]'] * (max_length -1 - len(sentenceTokens))\n",
    "        \n",
    "        posTokens += ['[posSEP]'] + ['[posPAD]'] * (max_length - 1 - len(posTokens) )\n",
    "        nerTokens += ['[nerSEP]'] + ['[nerPAD]'] * (max_length - 1 - len(nerTokens) )\n",
    "            \n",
    "        sentenceList.append(sentence)\n",
    "\n",
    "        sentenceTokenList.append(sentenceTokens)\n",
    "\n",
    "        bertSentenceIDs.append(tokenizer.convert_tokens_to_ids(sentenceTokens))\n",
    "        bertMasks.append([1] * (sentenceLength + 1) + [0] * (max_length -1 - sentenceLength ))\n",
    "        bertSequenceIDs.append([0] * (max_length))\n",
    "                             \n",
    "        posTokenList.append(posTokens)\n",
    "        nerTokenList.append(nerTokens)\n",
    "        \n",
    "        sentence = ''\n",
    "        sentenceTokens = ['[CLS]']\n",
    "        posTokens = ['[posCLS]']\n",
    "        nerTokens = ['[nerCLS]']\n",
    "        \n",
    "        sentence += ' ' + word\n",
    "        word_count = 0\n",
    "    \n",
    "    word_count += 1\n",
    "    addDict = addWord(word, pos, ner)\n",
    "\n",
    "    sentenceTokens += addDict['wordToken']\n",
    "    posTokens += addDict['posToken']\n",
    "    nerTokens += addDict['nerToken']\n",
    "\n",
    "# The first two list elements need to be removed. 1st line in file is a-typical, and 2nd line does not end a sentence   \n",
    "sentLengthList = sentLengthList[2:]\n",
    "sentenceTokenList = sentenceTokenList[2:]\n",
    "bertSentenceIDs = bertSentenceIDs[2:]\n",
    "bertMasks = bertMasks[2:]\n",
    "bertSequenceIDs = bertSequenceIDs[2:]\n",
    "posTokenList = posTokenList[2:]\n",
    "nerTokenList = nerTokenList[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did this do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(sentLengthList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1198, 202, 2426, 7902, 907, 538, 6096, 1540, 1540, 136, 619, 272, 537, 12551, 326, 10456, 13035, 2403, 10319, 186, 3466, 125, 10456, 23642, 606, 111, 3214, 125, 111, 11070, 1540, 1540, 768, 345, 1327, 2877, 253, 5555, 1791, 146, 20234, 550, 282, 3657, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSentenceIDs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'reported', 'that', 'her', 'foot', 'had', 'been', 'blue', '\"', '\"', 'and', 'there', 'were', 'no', 'Doppler', '##able', 'pulses', 'Color', 'later', 'returned', 'The', 'absence', 'of', 'pulses', 'persisted', 'over', 'the', 'course', 'of', 'the', 'night', '\"', '\"', 'after', 'which', 'point', 'she', 'was', 'referred', 'back', 'to', 'Lar', '##gr', '##ine', 'Medical', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[nerCLS]', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'nerX', 'nerX', 'O', '[nerSEP]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]', '[nerPAD]']\n"
     ]
    }
   ],
   "source": [
    "print(nerTokenList[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertMasks[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks right. Everything past the '[SEP]' token, i.e., the '[nerSEP]' label, is masked out. Also the sequence_ids are correct: there is only one sentence, so all ids should have the same value of zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(bertSequenceIDs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. \n",
    "\n",
    "\n",
    "### III.3. Initial Data Analysis<a id=\"analysis\" />\n",
    "\n",
    "It is important to understand the dataset prior to doing any modeling or training. First, what are the length of the original sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.000e+00, 0.000e+00, 1.900e+01, 0.000e+00, 0.000e+00, 6.300e+01,\n",
       "        0.000e+00, 0.000e+00, 8.900e+01, 0.000e+00, 1.440e+02, 0.000e+00,\n",
       "        0.000e+00, 1.800e+02, 0.000e+00, 0.000e+00, 2.280e+02, 0.000e+00,\n",
       "        2.640e+02, 0.000e+00, 0.000e+00, 2.950e+02, 0.000e+00, 0.000e+00,\n",
       "        2.890e+02, 0.000e+00, 2.720e+02, 0.000e+00, 0.000e+00, 3.030e+02,\n",
       "        0.000e+00, 0.000e+00, 2.860e+02, 0.000e+00, 0.000e+00, 2.620e+02,\n",
       "        0.000e+00, 2.780e+02, 0.000e+00, 0.000e+00, 2.410e+02, 0.000e+00,\n",
       "        0.000e+00, 2.010e+02, 0.000e+00, 2.110e+02, 0.000e+00, 0.000e+00,\n",
       "        1.830e+02, 0.000e+00, 0.000e+00, 1.640e+02, 0.000e+00, 1.700e+02,\n",
       "        0.000e+00, 0.000e+00, 1.640e+02, 0.000e+00, 0.000e+00, 1.660e+02,\n",
       "        0.000e+00, 3.013e+03]),\n",
       " array([40.        , 40.37096774, 40.74193548, 41.11290323, 41.48387097,\n",
       "        41.85483871, 42.22580645, 42.59677419, 42.96774194, 43.33870968,\n",
       "        43.70967742, 44.08064516, 44.4516129 , 44.82258065, 45.19354839,\n",
       "        45.56451613, 45.93548387, 46.30645161, 46.67741935, 47.0483871 ,\n",
       "        47.41935484, 47.79032258, 48.16129032, 48.53225806, 48.90322581,\n",
       "        49.27419355, 49.64516129, 50.01612903, 50.38709677, 50.75806452,\n",
       "        51.12903226, 51.5       , 51.87096774, 52.24193548, 52.61290323,\n",
       "        52.98387097, 53.35483871, 53.72580645, 54.09677419, 54.46774194,\n",
       "        54.83870968, 55.20967742, 55.58064516, 55.9516129 , 56.32258065,\n",
       "        56.69354839, 57.06451613, 57.43548387, 57.80645161, 58.17741935,\n",
       "        58.5483871 , 58.91935484, 59.29032258, 59.66129032, 60.03225806,\n",
       "        60.40322581, 60.77419355, 61.14516129, 61.51612903, 61.88709677,\n",
       "        62.25806452, 62.62903226, 63.        ]),\n",
       " <a list of 62 Patch objects>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentenceLengths= [l for l in sentLengthList]\n",
    "\n",
    "plt.hist(np.array(sentenceLengths), bins=(max_length-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An average sentence length of ~25 (incl. extra tokens!) is roughly expected. It turns out that on these types of corpora an average sentence length of ~20 tends to be seen. The big spike on the right obviously corresponds to all sentences that we had to truncate. \n",
    "\n",
    "Next, we analyze the distribution of ner labels. First, we assign numbers to the labels and look at the overall distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numSentences = len(bertSentenceIDs)\n",
    "\n",
    "nerClasses = pd.DataFrame(np.array(nerTokenList).reshape(-1))\n",
    "nerClasses.columns = ['tag']\n",
    "nerClasses.tag = pd.Categorical(nerClasses.tag)\n",
    "nerClasses['cat'] = nerClasses.tag.cat.codes\n",
    "nerClasses['sym'] = nerClasses.tag.cat.codes\n",
    "nerLabels = np.array(nerClasses.cat).reshape(numSentences, -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7fc947977320>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nerClasses[['cat']].hist(bins=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a lot of tables with value 16+... Let's see which labels these label numbers corresponds to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>cat</th>\n",
       "      <th>occurences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-do</td>\n",
       "      <td>0</td>\n",
       "      <td>3913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-du</td>\n",
       "      <td>1</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-f</td>\n",
       "      <td>2</td>\n",
       "      <td>3537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-m</td>\n",
       "      <td>3</td>\n",
       "      <td>8089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-mo</td>\n",
       "      <td>4</td>\n",
       "      <td>2935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-r</td>\n",
       "      <td>5</td>\n",
       "      <td>1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I-do</td>\n",
       "      <td>6</td>\n",
       "      <td>3502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I-du</td>\n",
       "      <td>7</td>\n",
       "      <td>1103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I-f</td>\n",
       "      <td>8</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I-m</td>\n",
       "      <td>9</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I-mo</td>\n",
       "      <td>10</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I-r</td>\n",
       "      <td>11</td>\n",
       "      <td>1099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>O</td>\n",
       "      <td>12</td>\n",
       "      <td>235243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[nerCLS]</td>\n",
       "      <td>13</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[nerPAD]</td>\n",
       "      <td>14</td>\n",
       "      <td>51766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[nerSEP]</td>\n",
       "      <td>15</td>\n",
       "      <td>7488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nerX</td>\n",
       "      <td>16</td>\n",
       "      <td>145819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tag  cat  occurences\n",
       "0       B-do    0        3913\n",
       "1       B-du    1         520\n",
       "2        B-f    2        3537\n",
       "3        B-m    3        8089\n",
       "4       B-mo    4        2935\n",
       "5        B-r    5        1555\n",
       "6       I-do    6        3502\n",
       "7       I-du    7        1103\n",
       "8        I-f    8        1196\n",
       "9        I-m    9        3863\n",
       "10      I-mo   10         116\n",
       "11       I-r   11        1099\n",
       "12         O   12      235243\n",
       "13  [nerCLS]   13        7488\n",
       "14  [nerPAD]   14       51766\n",
       "15  [nerSEP]   15        7488\n",
       "16      nerX   16      145819"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nerDistribution = (nerClasses.groupby(['tag', 'cat']).agg({'sym':'count'}).reset_index()\n",
    "                   .rename(columns={'sym':'occurences'}))\n",
    "\n",
    "numNerClasses = nerDistribution.tag.nunique()\n",
    "\n",
    "nerDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting. 12 corresponds to 'O', and all 'extension' labels (i.e., those that were not part of the original data) occur at 13+. \n",
    "\n",
    "'O' is the most common token - by far.\n",
    "\n",
    "### III.4. Baseline: Always picking 'Other'<a id=\"baseline\" />\n",
    "\n",
    "Let's see what a baseline would give for the actual text tokens, if I ALWAYS chose the most common token 'O':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12    0.882147\n",
       "Name: occurences, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O_occurences = nerDistribution.loc[nerDistribution.tag == 'O','occurences']\n",
    "All_occurences = nerDistribution[nerDistribution.cat < 13]['occurences'].sum()\n",
    "\n",
    "O_occurences/All_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **88.5%** is the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III.5. Train/Test Split and Final Data Preparation<a id=\"split\" />\n",
    "\n",
    "In the last step we need to prepare both labels and input for the model, including the train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_inputs = np.array([bertSentenceIDs, bertMasks, bertSequenceIDs])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(bertSentenceIDs, nerLabels, \n",
    "                                                            random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(bertMasks, bertSentenceIDs,\n",
    "                                             random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_masks[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 231, 22927, 138, 294, 16027, 30105, 864, 186, 1607, 441, 105, 3290, 125, 4330, 4330, 1595, 803, 1540, 1540, 368, 253, 201, 2311, 3990, 2858, 125, 5665, 30155, 4473, 345, 253, 1007, 3857, 13572, 4440, 193, 824, 193, 198, 4473, 14593, 2529, 3427, 125, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(tr_inputs[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 12, 12, 16, 12, 12, 16, 16, 12, 12, 12, 12, 12, 12,  5,  5, 12,\n",
       "       12, 12, 16, 12, 12, 12, 12, 12, 12, 12,  3, 16,  9, 12, 12,  0,  6,\n",
       "        4,  2, 12, 12, 12, 12,  3,  0,  6, 12, 12, 15, 14, 14, 14, 14, 14,\n",
       "       14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14], dtype=int8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_tags[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'on', 'the', '2', 'of', 'September', 'PAS', '##T', 'SU', '##RG', '##ICAL', 'HI', '##ST', '##ORY', ':', 'Not', '##able', 'for', 'the', 'above', '\"', '\"', 'as', 'well', 'as', 'deb', '##rid', '##ements', 'of', 'her', 'to', '##e', 'amp', '##utation', 'wound', 'site', 'AD', '##MI', '##SS', '##ION', 'MED', '##ICATIONS', ':', 'Col', '##ace', '100', 'mg', 'b', '.', 'i', '.', 'd', '\"', '\"', 'insulin', 'Le', '##nt', '##e', '12', 'units', 'subc', '##u', '[SEP]', '[PAD]']\n"
     ]
    }
   ],
   "source": [
    "print(sentenceTokenList[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags, dtype=torch.long, device=device)\n",
    "val_tags = torch.tensor(val_tags, dtype=torch.long, device=device)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config = BertConfig.from_json_file('/root/biobert_v1.0_pubmed_pmc/bert_config.json')\n",
    "model = BertForTokenClassification.from_pretrained('/root/scibert_scivocab_cased', num_labels=nerDistribution['tag'].count())\n",
    "#model = BertForTokenClassification.from_pretrained(\"scibert-basevocab-cased\", num_labels=len(tag2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(31090, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): FusedLayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (classifier): Linear(in_features=768, out_features=17, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "bert.embeddings.position_embeddings.weight\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "bert.embeddings.LayerNorm.weight\n",
      "bert.embeddings.LayerNorm.bias\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "bert.pooler.dense.weight\n",
      "bert.pooler.dense.bias\n",
      "classifier.weight\n",
      "classifier.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():                \n",
    "    print (name)\n",
    "    #if name.startswith('embeddings'):\n",
    "    #    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report, accuracy_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5655212122682146\n",
      "Validation loss: 0.23993235950668654\n",
      "Validation Accuracy: 0.8316759940905448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   2%|▏         | 1/50 [02:39<2:10:18, 159.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.5130674002751032\n",
      "Recall: 0.4814974182444062\n",
      "Train loss: 0.20543603203590446\n",
      "Validation loss: 0.14329310289273658\n",
      "Validation Accuracy: 0.8581746419270834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   4%|▍         | 2/50 [05:19<2:07:42, 159.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7182858534209886\n",
      "Recall: 0.7129047849202513\n",
      "Train loss: 0.12526998836635414\n",
      "Validation loss: 0.1104931343967716\n",
      "Validation Accuracy: 0.866680438701923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   6%|▌         | 3/50 [07:59<2:05:12, 159.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7561499880582756\n",
      "Recall: 0.7366216845044207\n",
      "Train loss: 0.08629885345909268\n",
      "Validation loss: 0.10039241674045722\n",
      "Validation Accuracy: 0.8692047901642628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:   8%|▊         | 4/50 [10:38<2:02:17, 159.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7979502196193266\n",
      "Recall: 0.7936893203883495\n",
      "Train loss: 0.06530304883399281\n",
      "Validation loss: 0.09538183050851028\n",
      "Validation Accuracy: 0.8692032251602564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  10%|█         | 5/50 [13:18<1:59:51, 159.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7700210133084286\n",
      "Recall: 0.734521158129176\n",
      "Train loss: 0.050053893795934334\n",
      "Validation loss: 0.09431339877968033\n",
      "Validation Accuracy: 0.8712565104166666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█▏        | 6/50 [15:59<1:57:17, 159.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8014117647058824\n",
      "Recall: 0.7698915009041591\n",
      "Train loss: 0.04023201101110869\n",
      "Validation loss: 0.09832621598616242\n",
      "Validation Accuracy: 0.8703597631209936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  14%|█▍        | 7/50 [18:38<1:54:30, 159.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.7891469303288111\n",
      "Recall: 0.7425356988316746\n",
      "Train loss: 0.032146436563953405\n",
      "Validation loss: 0.09548972143481176\n",
      "Validation Accuracy: 0.8717197516025642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  16%|█▌        | 8/50 [21:17<1:51:38, 159.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8098391674550617\n",
      "Recall: 0.7817351598173516\n",
      "Train loss: 0.026441645155267975\n",
      "Validation loss: 0.0987687036395073\n",
      "Validation Accuracy: 0.8714646559495192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  18%|█▊        | 9/50 [23:56<1:48:53, 159.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.808659217877095\n",
      "Recall: 0.7692648361381754\n",
      "Train loss: 0.021571599264845465\n",
      "Validation loss: 0.10014227622499068\n",
      "Validation Accuracy: 0.872837164463141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  20%|██        | 10/50 [26:35<1:46:08, 159.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8235574630424416\n",
      "Recall: 0.8010204081632653\n",
      "Train loss: 0.01787774577092432\n",
      "Validation loss: 0.10145549879719813\n",
      "Validation Accuracy: 0.8728074293870192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  22%|██▏       | 11/50 [29:14<1:43:30, 159.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8219821512447159\n",
      "Recall: 0.7882882882882883\n",
      "Train loss: 0.015466280219749816\n",
      "Validation loss: 0.1111982266108195\n",
      "Validation Accuracy: 0.873081305088141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  24%|██▍       | 12/50 [31:54<1:41:00, 159.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8165399239543726\n",
      "Recall: 0.791705069124424\n",
      "Train loss: 0.013218843336195036\n",
      "Validation loss: 0.11836678721010685\n",
      "Validation Accuracy: 0.8730327899639424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  26%|██▌       | 13/50 [34:34<1:38:20, 159.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8229141906346567\n",
      "Recall: 0.7980636237897649\n",
      "Train loss: 0.011071518604241982\n",
      "Validation loss: 0.11244797970478733\n",
      "Validation Accuracy: 0.8729216746794872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  28%|██▊       | 14/50 [37:13<1:35:41, 159.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8211420481359131\n",
      "Recall: 0.7909090909090909\n",
      "Train loss: 0.009325447396300203\n",
      "Validation loss: 0.12391890569900472\n",
      "Validation Accuracy: 0.8736431415264424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  30%|███       | 15/50 [39:53<1:33:02, 159.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8268182895048566\n",
      "Recall: 0.7993586807146129\n",
      "Train loss: 0.008857015238951238\n",
      "Validation loss: 0.1200571369069318\n",
      "Validation Accuracy: 0.8733692658253206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  32%|███▏      | 16/50 [42:33<1:30:27, 159.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8202434948675101\n",
      "Recall: 0.798698279869828\n",
      "Train loss: 0.007554800841092216\n",
      "Validation loss: 0.12121105783929427\n",
      "Validation Accuracy: 0.8735382862580128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  34%|███▍      | 17/50 [45:12<1:27:45, 159.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.821547223540579\n",
      "Recall: 0.7954963235294118\n",
      "Train loss: 0.006404846498380764\n",
      "Validation loss: 0.12443368773286541\n",
      "Validation Accuracy: 0.8736118414463142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  36%|███▌      | 18/50 [47:51<1:25:00, 159.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8296261239943209\n",
      "Recall: 0.8011882998171846\n",
      "Train loss: 0.0063792352169593225\n",
      "Validation loss: 0.12951372967412075\n",
      "Validation Accuracy: 0.8728700295472757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|███▊      | 19/50 [50:30<1:22:21, 159.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8202830188679244\n",
      "Recall: 0.7897366030881017\n",
      "Train loss: 0.005264005448583125\n",
      "Validation loss: 0.13047782999152938\n",
      "Validation Accuracy: 0.8734162159455128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  40%|████      | 20/50 [53:09<1:19:38, 159.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8272102393932211\n",
      "Recall: 0.8000917010545622\n",
      "Train loss: 0.005070425019245286\n",
      "Validation loss: 0.13245934527367353\n",
      "Validation Accuracy: 0.873996832431891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  42%|████▏     | 21/50 [55:49<1:17:00, 159.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8325748502994013\n",
      "Recall: 0.8132896583996256\n",
      "Train loss: 0.004824203330365791\n",
      "Validation loss: 0.13907781460632881\n",
      "Validation Accuracy: 0.8744976337139424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  44%|████▍     | 22/50 [58:28<1:14:23, 159.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8401177047572339\n",
      "Recall: 0.8397058823529412\n",
      "Train loss: 0.004796839168270988\n",
      "Validation loss: 0.13734647817909718\n",
      "Validation Accuracy: 0.8743739983974358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  46%|████▌     | 23/50 [1:01:08<1:11:47, 159.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8360931125509959\n",
      "Recall: 0.8182245185533115\n",
      "Train loss: 0.0042408284785278956\n",
      "Validation loss: 0.1333031253889203\n",
      "Validation Accuracy: 0.8736008864182692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  48%|████▊     | 24/50 [1:03:49<1:09:13, 159.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8298774740810556\n",
      "Recall: 0.7982774252039891\n",
      "Train loss: 0.0037728696127733333\n",
      "Validation loss: 0.12975909607484937\n",
      "Validation Accuracy: 0.8740390875400642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  50%|█████     | 25/50 [1:06:29<1:06:37, 159.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8346793349168646\n",
      "Recall: 0.8089318600368324\n",
      "Train loss: 0.0037372021416425087\n",
      "Validation loss: 0.13460492870459953\n",
      "Validation Accuracy: 0.8742221930088142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  52%|█████▏    | 26/50 [1:09:09<1:03:58, 159.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8332534738859607\n",
      "Recall: 0.8141385767790262\n",
      "Train loss: 0.003375693290992044\n",
      "Validation loss: 0.13785639218986034\n",
      "Validation Accuracy: 0.874538323818109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  54%|█████▍    | 27/50 [1:11:48<1:01:15, 159.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8341830541393543\n",
      "Recall: 0.8255646323882748\n",
      "Train loss: 0.003428829784485207\n",
      "Validation loss: 0.13493835522482792\n",
      "Validation Accuracy: 0.8739577073317308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  56%|█████▌    | 28/50 [1:14:29<58:38, 159.94s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8333333333333334\n",
      "Recall: 0.8072677092916284\n",
      "Train loss: 0.003087374995935982\n",
      "Validation loss: 0.14262666118641695\n",
      "Validation Accuracy: 0.8742722731370192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  58%|█████▊    | 29/50 [1:17:09<56:02, 160.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8342501793829228\n",
      "Recall: 0.8138124125058329\n",
      "Train loss: 0.0036431996504775075\n",
      "Validation loss: 0.13455250083158413\n",
      "Validation Accuracy: 0.8742519280849358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  60%|██████    | 30/50 [1:19:49<53:23, 160.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.840705825477399\n",
      "Recall: 0.8284897570271558\n",
      "Train loss: 0.0031400189242713037\n",
      "Validation loss: 0.13742686187227568\n",
      "Validation Accuracy: 0.8748403695913461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  62%|██████▏   | 31/50 [1:22:29<50:42, 160.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8369171297414835\n",
      "Recall: 0.8243693479295574\n",
      "Train loss: 0.003474522480642935\n",
      "Validation loss: 0.14782896544784307\n",
      "Validation Accuracy: 0.8749029697516025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  64%|██████▍   | 32/50 [1:25:09<47:59, 159.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8465071307710902\n",
      "Recall: 0.8342067651262506\n",
      "Train loss: 0.0028134420399898354\n",
      "Validation loss: 0.13605719742675623\n",
      "Validation Accuracy: 0.8734975961538461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  66%|██████▌   | 33/50 [1:27:48<45:13, 159.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8193227563343594\n",
      "Recall: 0.7917620137299771\n",
      "Train loss: 0.0026610868422825428\n",
      "Validation loss: 0.15010499395430088\n",
      "Validation Accuracy: 0.8740218724959936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  68%|██████▊   | 34/50 [1:30:28<42:36, 159.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8357178095707943\n",
      "Recall: 0.8402777777777778\n",
      "Train loss: 0.0026300584422772025\n",
      "Validation loss: 0.1440432995247344\n",
      "Validation Accuracy: 0.8744866786858975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  70%|███████   | 35/50 [1:33:08<39:56, 159.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8343294286397324\n",
      "Recall: 0.8135198135198135\n",
      "Train loss: 0.0020580888367950434\n",
      "Validation loss: 0.14315873819092909\n",
      "Validation Accuracy: 0.874782464443109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  72%|███████▏  | 36/50 [1:35:47<37:15, 159.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8433212996389893\n",
      "Recall: 0.8275862068965517\n",
      "Train loss: 0.0019600191686006694\n",
      "Validation loss: 0.14680077166606983\n",
      "Validation Accuracy: 0.8751878004807692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  74%|███████▍  | 37/50 [1:38:28<34:38, 159.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8460417678484701\n",
      "Recall: 0.8375\n",
      "Train loss: 0.002101214622072622\n",
      "Validation loss: 0.14986615752180418\n",
      "Validation Accuracy: 0.8750563401442308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  76%|███████▌  | 38/50 [1:41:08<31:58, 159.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8397683397683398\n",
      "Recall: 0.8262108262108262\n",
      "Train loss: 0.002569268027275538\n",
      "Validation loss: 0.1439256053417921\n",
      "Validation Accuracy: 0.8751690204326924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  78%|███████▊  | 39/50 [1:43:46<29:15, 159.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8385542168674699\n",
      "Recall: 0.8238636363636364\n",
      "Train loss: 0.0021494247108740376\n",
      "Validation loss: 0.14514667633920908\n",
      "Validation Accuracy: 0.8741611578525642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  80%|████████  | 40/50 [1:46:26<26:36, 159.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.835941204362257\n",
      "Recall: 0.8087155963302752\n",
      "Train loss: 0.0025166653078261838\n",
      "Validation loss: 0.14324937916050354\n",
      "Validation Accuracy: 0.8749139247796475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  82%|████████▏ | 41/50 [1:49:06<23:57, 159.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8425634824667473\n",
      "Recall: 0.8307105388650453\n",
      "Train loss: 0.0017876883928917273\n",
      "Validation loss: 0.14447294470543662\n",
      "Validation Accuracy: 0.8750563401442308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  84%|████████▍ | 42/50 [1:51:45<21:16, 159.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8442307692307693\n",
      "Recall: 0.827521206409048\n",
      "Train loss: 0.0017439705881503106\n",
      "Validation loss: 0.14078185288235545\n",
      "Validation Accuracy: 0.8758184970953525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  86%|████████▌ | 43/50 [1:54:25<18:36, 159.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8453105968331303\n",
      "Recall: 0.8393807450411224\n",
      "Train loss: 0.0018001485242722423\n",
      "Validation loss: 0.13839663503070673\n",
      "Validation Accuracy: 0.8751377203525642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  88%|████████▊ | 44/50 [1:57:05<15:57, 159.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8455829542734019\n",
      "Recall: 0.825619448340346\n",
      "Train loss: 0.0013453776948188455\n",
      "Validation loss: 0.1559447661663095\n",
      "Validation Accuracy: 0.8750359950921475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  90%|█████████ | 45/50 [1:59:43<13:17, 159.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8407984420642648\n",
      "Recall: 0.8342995169082126\n",
      "Train loss: 0.0020610507594140673\n",
      "Validation loss: 0.14793345083793005\n",
      "Validation Accuracy: 0.874408428485577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  92%|█████████▏| 46/50 [2:02:24<10:38, 159.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.837142169834015\n",
      "Recall: 0.8211420481359132\n",
      "Train loss: 0.0019249682029793636\n",
      "Validation loss: 0.14990317542105913\n",
      "Validation Accuracy: 0.8746009239783654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  94%|█████████▍| 47/50 [2:05:04<07:59, 159.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8402479732951836\n",
      "Recall: 0.8172541743970315\n",
      "Train loss: 0.0014218272204674731\n",
      "Validation loss: 0.15663588357468447\n",
      "Validation Accuracy: 0.8740109174679488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  96%|█████████▌| 48/50 [2:07:43<05:19, 159.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8287853175561458\n",
      "Recall: 0.8159771754636234\n",
      "Train loss: 0.0017303293972950368\n",
      "Validation loss: 0.15379126432041326\n",
      "Validation Accuracy: 0.8739295372596154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  98%|█████████▊| 49/50 [2:10:23<02:39, 159.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.8345935727788281\n",
      "Recall: 0.804922515952598\n",
      "Train loss: 0.0013616353764639554\n",
      "Validation loss: 0.16079851426184177\n",
      "Validation Accuracy: 0.8746588291266025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch: 100%|██████████| 50/50 [2:13:02<00:00, 159.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.834942084942085\n",
      "Recall: 0.8214624881291548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "train_loss = []\n",
    "evaluation_loss = []\n",
    "f1score = []\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        # forward pass\n",
    "        loss = model(b_input_ids, token_type_ids=None,\n",
    "                     attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "    train_loss.append(tr_loss/nb_tr_steps)\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    for batch in valid_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "                                  attention_mask=b_input_mask, labels=b_labels)\n",
    "            logits = model(b_input_ids, token_type_ids=None,\n",
    "                           attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    evaluation_loss.append(eval_loss)\n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    pred_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == p_i).idxmax()][0] for p in predictions for p_i in p])\n",
    "    valid_tags = np.array([nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][0] for l in true_labels for l_i in l for l_ii in l_i])\n",
    "    valid_ids = [nerDistribution.loc[(nerDistribution['cat'] == l_ii).idxmax()][1] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    mask = (np.array(valid_ids) < 13)\n",
    "    #print(mask)\n",
    "    pred = np.ma.compressed(np.ma.MaskedArray(pred_tags, mask=~mask))\n",
    "    valid = np.ma.compressed(np.ma.MaskedArray(valid_tags, mask=~mask))\n",
    "    #print(pred.tolist())\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred.tolist(), valid.tolist())))\n",
    "    f1score.append(f1_score(pred.tolist(), valid.tolist()))\n",
    "    print(\"Recall: {}\".format(recall_score(pred.tolist(), valid.tolist())))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (1.3.0)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.6/site-packages (from scipy) (1.16.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_loss)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Traing Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(f1score)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.title(\"F1 Curve\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
